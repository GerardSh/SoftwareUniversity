# General
## HTTP Cookies
Малък файл с обикновен текст без изпълним код.
- Изпратен от сървъра до браузъра на клиента.
- Съхраняван от браузъра на устройството на клиента (компютър, таблет и т.н.). Това е едно от малкото неща, които можем да запишем с цел осигуряване на сигурността на потребителската машина.
- Съдържа малко количество данни за конкретен клиент и уебсайт.

Сървърът създава кукита, които изпраща към браузъра, а той ги връща обратно на всеки следващ рекуест. Вътре в кукито има двойки ключ-стойност (key-value pairs).

Според GDPR и директивата ePrivacy, трябва да уведомяваме потребителите, че използваме кукита, и да получаваме тяхното съгласие, преди да ги събираме. Това обикновено става чрез банер, който информира потребителите и им позволява да управляват предпочитанията си за кукитата. Като се съгласим да ползваме куки, дори тази информация се записва в куки.

Принципно има ограничение в размера на кукитата, но съвременните браузъри решават проблема, като ги разпадат на повече части. Така можем да съберем много голяма информация в кукитата, но не е желателно, тъй като това увеличава размера на рекуеста.

Реално информацията в кукито са неща, които сървъра трябва да помни за нас. Понеже HTTP протокола е stateless - не помни нищо. Каквото и да е имало в даден рекуест, то е загубено в следващия. След първия рекуест, на следващия сървъра вече не помни нищо за нас. Кукито се явява като work around, като в него записваме нещата, които искаме да бъдат запомнени за нас.
### Usage
1. Управление на сесии - това е най-честата употреба на кукита, като също се използват за колички за пазаруване, резултати от игри или всичко друго, което сървърът трябва да запомни.  Те могат да съхраняват информация за самия потребител, като кой е логнат, заедно с неговите допълнителни свойства. В тях се намират така наречените клейма (claims), като напоследък **claim-based identity** се използва от всички, включително и от ASP.NET. Когато се логваме някъде, някой проверява дали имаме право да се идентифицираме, като първо се проверява даден критерий, като потребителско име и парола. След като се установи, че сме ние, се проверява дали има допълнителна информация, например имейл, имена, роля и друга информация. Понеже вече сме идентифицирани и се знае кои сме, системата може да твърди, че ние сме този човек и имаме съответната информация. Въпросният провайдър, независимо кой е той, издава клеймата (claims) — твърдения за нас. Например: първо твърдение — това е името на човека, второ твърдение — той е администратор и т.н. Провайдърът записва тези твърдения в кукито и оттук нататък, всеки път, когато това куки се върне към сървъра, той ще знае тези твърдения. Няма нужда да ги проверява, защото има вяра в провайдъра и неговите твърдения. Всички тези твърдения се приемат за верни, докато кукито е валидно. В момента, в който изтече или бъде анулирано (например при **sign out**), сървърът забравя тези данни, защото не ги съхранява на друго място.

2. Персонализация - потребителски предпочитания, теми и други персонализирани настройки.

3. Проследяване - записване и анализиране на потребителско поведение. Може да се записва информация за самата активност в браузъра, като например колко хора са посетили дадена страница и колко време са се задържали на нея. Тази информация ни дава възможност да преценим кое е интересно за клиентите и кое не се посещава, като така можем да оптимизираме съдържанието и функционалността на сайта.

4. Да пазим информация, която преди това е била въведена във форма, е една от основните функции на кукитата и сесиите. Когато потребителят попълни форма и я изпрати, сървърът може да запише определена част от информацията (например потребителски имена, настройки или предпочитания) в кукита или сесийни данни, за да я запази и да я използва в бъдеще, без да се налага потребителят да въвежда отново същите данни.
### Stateless HTTP - The Problem
Сървърът не знае дали два рекуеста идват от един и същ клиент, което води до проблеми:

За всяка операция, която искаме да извършим на даден сайт, трябва да се автентикираме отново.

Друга необходима информация като количка с покупки, запазени резултати от игри, или вече сме избрали нещо на страницата, при следващия рекуест то изчезва и тн.

Няма как да се персонализира страницата.
### Stateless HTTP - The Cookie Solution
Въпреки че HTTP протоколът е **stateless**, той има механизъм за запомняне, наречен **cookie**. Чрез кукито сървърът може да помни състоянието между рекуестите. Например, когато се логнем с даден рекуест и сървърът ни върне отговор, той може да ни изпрати куки, в което е записано кой сме. В следващия рекуест, когато върнем кукито към сървъра, той вече знае кой се обръща към него, като чете информацията в кукито.

Куки и сесии често се комбинират, защото може да имаме куки, което съдържа само идентификатор на сесия. Сървърът знае откъде да извлече тази сесия, която обикновено се пази на сървъра. Важно е обаче **къде** точно се съхранява тази информация, защото това определя сигурността и достъпността на сесийните данни.
### How Are Cookies Used
Отговорът на сървъра съдържа куки, което бива запазено, чрез **Set-Cookie** header:

```
HTTP/1.1 200 OK
Set-Cookie: lang=en
```

Заявката от клиента съдържа съответното куки, което изпраща към сървъра, чрез **Cookie** header-a, ако е направена към същия domain:

```
GET www.example.bg HTTP/1.1
Cookie: lang=en
```

Това означава, че при всяко следващо посещение на същия сайт, браузърът изпраща кукито обратно към сървъра, за да може той да запомни предишните настройки, като например избран език (в случая `lang=en`).

Така, сървърът изпраща информация за куки, което браузърът запазва, а при следващите рекуести браузърът връща тези кукита обратно към сървъра.

Когато браузърът получи куки от даден сайт, той ги запазва локално. При всяко следващо искане към този същия домейн, браузърът автоматично включва съответните кукита в **Cookie** header-а на заявката. Това позволява на сървъра да "помни" информация като идентификация на потребителя или настройки. Това гарантира, че само правилните кукита ще бъдат изпращани на сървъра за съответния домейн.
### Cookie Structure
Кукито се състои от **Name**, **Value** и **Attributes** (по избор).

Атрибутите са **ключ-стойност** двойки с допълнителна информация.

Атрибутите не се включват в заявките.

Атрибутите се използват от клиента за управление на кукитата - да кажат на клиента, какво трябва да направи с даденото куки.

Пример за Set-Cookie header:

```
Set-Cookie: SSID=Ap4P…GTEq; Domain=foo.com; Path=/;
Expires=Wed, 13 Jan 2021 22:23:01 GMT; Secure; HttpOnly
```

Обяснение на атрибутите:

- **`SSID=Ap4P…GTEq`**: Това е информацията, която ще се препраща към всеки рекуест.

- **Domain=foo.com**: Кукито ще бъде изпратено само на домейна **foo.com**.

- **Path=/**: Кукито ще бъде изпратено за всички пътища на домейна.

- **Expires**: Определя кога кукито ще изтече. Ако не е зададено, кукито ще изтече при затваряне на браузъра.

- **Secure**: Кукито ще бъде изпратено само по сигурни (HTTPS) връзки.

- **`HttpOnly`**: Кукито не може да бъде достъпно чрез JavaScript, като се защитава от XSS атаки.
### Scope
Означава областта, в която действа дадено нещо. Когато говорим за кукита, ние определяме обхвата им чрез домейна (domain) и пътя (path). Целта е да гарантираме, че кукито няма да бъде изпратено към друг. Ако искаме то да бъде валидно само за определена част от нашето приложение, уточняваме пътя, като всички страници под този път в йерархията също ще получават кукито. По този начин може да разграничим, ако примерно имаме две area на нашето приложение - една администраторска и една потребителска, кукито да важи само за една от тях, рядко се налага. По честно кукитата са на основния път, но принципно е възможно.

- Domain – посочва уебсайта, към който принадлежи кукито. Ние така указваме кой сървър трябва да го получава.

- Path – указва пътя в URL-а, който трябва да съществува в заявката, за да бъде изпратен Cookie header-ът. С това ние ограничаваме действието на кукито само до определена част от приложението.

```
Set-Cookie: SSID=Ap4P…GTEq; Domain=foo.com; Path=/;
Expires=Wed, 13 Jan 2021 22:23:01 GMT; Secure; HttpOnly
```
### Lifetime
Куки файловете имат срок на действие, който се определя от атрибутите Expires и Max-Age.

- Expires – определя датата, на която браузърът трябва да изтрие кукито.

- По подразбиране куки файловете се изтриват в края на сесията. Браузърите обикновено приемат за край на сесията затварянето на целия браузър, а не само на таба. Въпреки това, това не винаги е гарантирано, тъй като някои браузъри могат да поддържат сесии активни дори след затваряне на прозореца.

- Max-Age – интервал от секунди, след който кукито ще бъде изтрито.

```
Set-Cookie: SSID=Ap4P…GTEq; Domain=foo.com; Path=/;
Expires=Wed, 13 Jan 2021 22:23:01 GMT; Secure; HttpOnly
```
### Security
Сигурността на кукитата се постига чрез използване на специални флагове, които нямат стойности, а само указания за браузъра:

- **Secure** – указва на браузъра да използва кукитата само през сигурни/шифровани връзки (например HTTPS).

- **`HttpOnly`** – определя, че кукито не може да бъде достъпвано чрез клиентски езици за скриптиране като JavaScript.

Пример за Set-Cookie header с тези атрибути:

```
Set-Cookie: SSID=Ap4P…GTEq; Domain=foo.com; Path=/; Expires=Wed, 13 Jan 2021 22:23:01 GMT; Secure; HttpOnly
```
### What is in the Cookie
Кукито е малък файл, съдържащ таблица с двойки **ключ-стойност**, които се използват за съхранение на информация, която сървърът и браузърът обменят. Всяка двойка ключ-стойност представлява конкретна информация, свързана с потребителската сесия, като например идентификатор на сесия или предпочитания за език.

Тази таблица от ключове и стойности се изпраща обратно към сървъра с всяка следваща заявка от същия клиент към сървъра, което позволява на сървъра да "помни" данни за клиента.

**Example Table:**

| **Attribute**            | **Value**                                 |
| ------------------------ | ----------------------------------------- |
| **Name**                 | ELOQUA                                    |
| **Content**              | GUID=50B3A712CDAA4A208FE95CE1F2BA7063     |
| **Domain**               | .oracle.com                               |
| **Path**                 | /                                         |
| **Send for**             | Any kind of connection                    |
| **Accessible to script** | Yes                                       |
| **Created**              | Monday, August 15, 2016 at 11:38:50 PM    |
| **Expires**              | Wednesday, August 15, 2018 at 11:38:51 PM |
### How to View Cookies
В **Google Chrome** можем да видим кукитата, като следваме тези стъпки:

1. Натискаме **F12** или **Ctrl + Shift + I**, за да отворим инструментите за разработчици.

2. Отиваме в таба **Application** (горе в инструментите).

3. В лявото меню избираме **Cookies** и след това кликваме на домейна, за който искаме да видим кукитата.

4. Ще се появи списък с всички кукита, които сървърът е изпратил за този домейн.

Там можем да видим детайли за всяко куки, като име, стойност, дата на изтичане и други атрибути.
### Third Party Cookies
Бисквитките на трети страни са бисквитки, поставени от домейн, различен от този на уебсайта, който посещаваме. Те се използват основно за реклама и проследяване на активността ни в интернет. Когато посетим сайт, външни мрежи, като рекламни услуги, могат да поставят бисквитки в браузъра ни.

**Как работят:**

1. Посещаваме сайт.

2. Външни източници (като рекламни мрежи) поставят бисквитки.

3. Те проследяват поведението ни през различни сайтове.

Проблеми с конфиденциалността:

- Могат да проследяват поведението ни без нашето съгласие.

- Някои браузъри ги блокират по подразбиране за защита на конфиденциалността.

**Регулации:**

- Законодателства като GDPR изискват съгласие за поставяне на тези бисквитки.

Общо взето, бисквитките на трети страни се използват за проследяване и таргетиране на реклами, но имат проблеми с конфиденциалността, което води до регулации и блокиране от браузъри.
## HTTP Sessions
**Сесии** са начин за съхранение на информация за потребител, която да бъде използвана през множество страници в уеб приложение. Тази информация се запазва през цялото време на взаимодействието на потребителя с уебсайта, дори когато той навигира между различни страници, като например `/login`, `/home`, и `/products`.

**Какво са сесиите?**

- **Сесиите** позволяват на уеб приложението да проследява дейността и състоянието на потребителя през множество страници, без да е необходимо да се въвеждат или изпращат отново данни.

- Обикновено, **сесията** съхранява данни като автентикация на потребителя (например дали потребителят е влязъл в системата) или други предпочитания (като съдържание в пазарска количка).

- Сесиите обикновено се съхраняват на сървъра, а **идентификаторът на сесията** се изпраща към клиента (обикновено като бисквитка), за да свърже потребителя с данните, съхранени на сървъра. Възможно е също да се изпрати като параметър в заявката (например в **URL**), но това носи сериозен риск, тъй като сесийните данни могат да бъдат видими в адресната лента, логове или дори да бъдат подслушвани от неоторизирани лица. Това може да доведе до кражба на сесията чрез атаки като **session fixation** или **session hijacking**.

**Пример:**

Потребителят **Тео** влиза в уеб приложение:

1. **Страница за вход**: Потребителят влиза на `/login`. Създава се сесия на сървъра и на **Тео** се присвоява уникален идентификатор на сесията.

2. **Начална страница**: Когато **Тео** премине към `/home`, идентификаторът на сесията се изпраща с заявката, което позволява на сървъра да идентифицира, че сесията принадлежи на **Тео**.

3. **Страница с продукти**: На `/products` сървърът използва идентификатора на сесията, за да разбере, че **Тео** е все още влязъл в системата, и може да покаже персонализирано съдържание или препоръки за продукти.

**Как работи:**

- **Идентификатор на сесията**: Когато **Тео** влиза в системата, сървърът създава уникален идентификатор на сесията, който се съхранява като бисквитка в браузъра на **Тео**.

- Докато **Тео** навигира между страници (например `/home`, `/products`), идентификаторът на сесията се изпраща обратно към сървъра, което позволява на сървъра да свърже действията с текущата сесия на **Тео** и да извлече съответната информация.

**Съхранение на сесията:**

- Сесията може да съхранява всякаква съответна информация, като името на потребителя (например **Тео**), статус на влизане, предпочитания на потребителя или други данни, които могат да бъдат използвани през различните страници на уеб приложението.

В обобщение, **сесията** гарантира, че информацията за потребителя (като идентичността на **Тео**) се запазва през множество страници в уеб приложението, без да е необходимо потребителят да влиза отново или да въвежда данни многократно.
### Relation with Cookies
![](https://github.com/GerardSh/SoftwareUniversity/blob/main/99%20Attachments/Pasted%20image%2020250429145908.png)

При този вариант се създава нов идентификатор на сесия, където вече седи истинския идентификатор на потребителя. Проблема е че процеса е тежък и е на две стъпки - само за да разберем информацията на потребителя, трябва веднъж да минем през session store и след това да минем през базата да видим кой е потребителя и чак след това се минава отново през базата за да се свърши работа. Това не е много оптимален вариант.

По-чистият и сигурен подход е, когато срещу нашия **идентификатор за сесия** съхраняваме **цялата информация за потребителя** на сървъра, а не я предаваме към клиента. Обикновено това се реализира чрез **in-memory бази** като Redis, които позволяват бърз достъп до сесийните данни и лесно мащабиране при голям брой потребители, без да се компрометира сигурността.
### Sessions vs Cookies
| Feature              | Cookies                                                       | Sessions                                          |
| -------------------- | ------------------------------------------------------------- | ------------------------------------------------- |
| **Storage Location** | Съхраняват се на компютъра на потребителя (като текстов файл) | Съхраняват се на сървъра                          |
| **Expiration**       | Изтичат на зададена дата                                      | Изтичат при затваряне на браузъра                 |
| **Data Capacity**    | Могат да съхраняват ограничено количество данни               | Могат да съхраняват неограничено количество данни |
| **Dependency**       | Не зависят от сесията                                         | Зависят от кукито (обикновено session ID)         |
| **Security**         | По-слаба сигурност – съхраняват се в обикновен текст          | По-висока сигурност – данните са криптирани       |
| **Accessibility**    | Лесно достъпни от всеки                                       | Не могат да бъдат достъпени лесно                 |
Ако съхраняваме сесиите само на сървъра (в паметта му), при наличие на няколко сървъра (напр. 5), потребителят ще бъде свързан само с този сървър, на който е създадена сесията. Ако по-късно заявката му попадне на друг сървър, сесията няма да бъде намерена и ще изглежда като че не е логнат. Затова при scaled приложения се използва споделен storage (напр. Redis), достъпно от всички сървъри.

Сесията съхранява информация за потребителя на сървъра, а не в бисквитките. Куките се използват само за съхранение на **идентификатора на сесията**, който свързва потребителя със сървърната информация.

Трябва да задаваме **срок на валидност (expiration)** на сесиите, за да избегнем т.нар. **„зомби сесии“**. Когато потребителят затвори браузъра, бисквитката със session ID може да се изтрие, но сървърът не получава сигнал за това и продължава да съхранява сесията. Затова е добре да ползваме **sliding expiration** – например, при живот от 30 минути, ако потребителят изпрати заявка на 15-тата минута, времето се удължава с още 30 минути.

Как работи:

1. Потребителят влиза в системата и получава **`session_id`**, който се съхранява в браузъра като бисквитка.

2. При всяка заявка, браузърът изпраща **`session_id`** към сървъра.

3. Сървърът използва този идентификатор, за да извлече данни за потребителя (например настройки, състояние на вход и т.н.).

**Как се съхранява информацията:**

- **В паметта на сървъра** (RAM) за бързо и временно съхранение.

- **В база данни**, ако информацията трябва да се съхранява постоянно.

- **Във външни хранилища** като **Redis**, ако има множество сървъри.

**Предимства:**

- Безопасност: Данните се съхраняват на сървъра и не могат да бъдат променяни от потребителя.

- Може да се съхраняват повече и по-сигурни данни в сравнение с куки.

Основната разлика е:

- **В куки** съхраняваме **цялата информация** за потребителя (например данни за влизане, настройки и т.н.), което може да бъде уязвимо и да увеличи размера на куките.

- **В сесии** съхраняваме само **идентификатора на сесията (`session_id`)** в куки, който указва на сървъра коя информация принадлежи на конкретния потребител. Всичката същинска информация се съхранява **на сървъра**, което е по-сигурно и по-ефективно.
## Synchronous Programming
![](https://github.com/GerardSh/SoftwareUniversity/blob/main/99%20Attachments/Pasted%20image%2020250429171514.png)

Изпълнение на програмни компоненти един след друг.

Всяко действие се случва след предходното.

Компонентите изчакват завършването на предишните.

Ресурсите на програмата са достъпни през цялото време, тъй като изпълнението е последователно и всяка част от кода има достъп до резултатите от предишните стъпки. Информацията от Task 1 може да бъде ползвана в следващите таскове, където решим. Това не е валидно, когато имаме паралелна обработка.
### Drawbacks
**Ако един компонент е блокиран, цялата програма е блокирана**  
    В синхронно програмиране, ако един компонент трябва да изчака (например поради забавяне в мрежова връзка или файлови операции), това ще блокира изпълнението на целия процес, докато не се приключи с него.

**Потребителският интерфейс може да стане unresponsive**  
    Ако програмата блокира по време на синхронни операции, интерфейсът може да спре да реагира на действия на потребителя, като например натискания на бутони или въвеждане на текст.

**Не се използват всички ядра на процесора**  
    В синхронно изпълнение, само едно ядро от процесора се използва по време на изпълнение на програмата, което означава, че програмата не се възползва от възможностите за паралелна обработка, които предлагат многопроцесорните системи.

**Задачи, изискващи голямо натоварване на процесора, забавят изпълнението на всички други задачи**  
    Ако има тежки операции (например сложни изчисления), те могат да блокират изпълнението на други части от програмата, което води до значително забавяне.

**Достъпът до ресурси блокира цялата програма**  
    Достъпът до външни ресурси като файлове или мрежови връзки също може да блокира програмата, докато се изчака отговорът от сървъра или операцията с файла.

**Особено проблемно при използване на уеб ресурси**  
    Програмите, които зависят от уеб заявки (например API извиквания), може да блокират всичко, докато се изчака отговор от сървъра. Това е особено проблемно за UX, когато се използват уеб приложения, които се нуждаят от незабавна реакция на потребителя.
## Asynchronous Programming
![](https://github.com/GerardSh/SoftwareUniversity/blob/main/99%20Attachments/Pasted%20image%2020250429213543.png)

**Компонентите на програмата могат да се изпълняват паралелно**  
	Частите на програмата не се изпълняват задължително една след друга, а могат да вървят едновременно.

**Някои действия се изпълняват едновременно с други**  
	Примерно четене от файл и показване на прогрес може да се случват паралелно.

**Всяко действие може да се изпълнява в отделна нишка**  
	Това позволява на програмата да използва по-добре процесора, като разпределя задачите в различни ядра.

**Независимите компоненти не изчакват изпълнението на останалите**  
	Ако една задача не зависи от друга, тя може да се изпълни веднага, без да чака другите да приключат. За да ги пуснем на отделни нишки, тасковете не трябва да зависят един от друг – не трябва резултатът от единия да е нужен за работата на втория. Ако има такава зависимост, задачите трябва да се изпълнят в една нишка, защото няма смисъл да са в различни. Изключение е, ако искаме да освободим главната нишка за нещо друго – тогава можем да ги изкараме в две нишки.

**Ресурсите на програмата се споделят между нишките**  
	Променливи, файлове или база данни могат да се използват от различни нишки едновременно.

**Ако една нишка използва даден ресурс, другите не трябва да го използват едновременно**  
	Това е нужно, за да се избегнат конфликти, загуба на данни или непредвидено поведение в програмата.
### Benefits
Ако даден компонент е блокиран, останалите продължават да работят.  

Потребителският интерфейс (UI) работи отделно и остава responsive.  

Съвременните процесори имат няколко ядра, и всяко може да изпълнява една или повече нишки.  

Нишките се разпределят динамично между ядрата от операционната система.  

Задачи, изискващи много изчисления, се изпълняват на фонови (background) нишки.  

Достъпът до ресурси също се извършва на фонови нишки.  
### Drawbacks
Трудно е да се разбере кои части от кода се изпълняват в конкретен момент.  

По-трудно от обикновено е да се дебъгва.  

Необходимо е да се защитят ресурсите.  

Една нишка използва ресурс.  

Останалите нишки трябва да изчакат за достъп до същия ресурс.  

Синхронизацията на достъпа до ресурси е трудна.  

Могат да възникнат deadlock състояния (взаимно блокиране на нишки).  
### Code
```csharp
static void PrintNumbersInRange(int a, int b)
{
    for (int i = a; i <= b; i++)
    {
        Console.WriteLine(i);
    }
}

int n = int.Parse(Console.ReadLine());
PrintNumbersInRange(0, 100);
var task = Task.Run(() =>
    PrintNumbersInRange(100, 200));

Console.WriteLine("Done.");
task.Wait();
```

В този пример:

Методът `PrintNumbersInRange` отпечатва числата в зададен интервал.

`PrintNumbersInRange(0, 100)` се извиква в главната нишка.

 След това се стартира фонов `Task`, който извиква `PrintNumbersInRange(100, 200)`.

`Console.WriteLine("Done.")` се отпечатва веднага след стартирането на задачата, **преди** тя да завърши.

`task.Wait()` изчаква приключването на фоновата задача, преди програмата да завърши.
## Threads
Една **нишка (thread)** е основна единица за изпълнение на код.

Обикновено един процес (програма) използва повече от една нишка.

В .NET **винаги** има повече от една нишка, които са чисто служебни (например за garbage collector-а). Каквото и да пишем ние, то винаги е асинхронно, винаги има повече от една нишка, просто не се грижим ние за тях.

Всяка нишка има свързана с нея паметна област, наречена **Call Stack**. Там се съхраняват **локалните променливи**. Съхраняват се и **в момента извиканите методи** – в реда, в който са извикани.
### Instruction Execution
Всеки програмен код се превежда в инструкции за процесора (CPU инструкции).

Пример – изпълнение на инструкции:

**`Program.cs`**

```csharp
int a = 5;  
int b = 4;  
Console.WriteLine(a + b);  
```

**↓ Compilation ↓**

**`Program.exe`**

```css
00DA2655 mov dword ptr [ebp-40h],5  
00DA265C mov dword ptr [ebp-44h],4  
00DA2663 mov ecx,dword ptr [ebp-40h]  
00DA2666 add ecx,dword ptr [ebp-44h]  
00DA2669 call 73B5A920  
00DA266E nop  
```

Обяснение:

При компилация, C# кодът се превежда в ниско ниво инструкции.

Всяка инструкция отговаря на конкретна операция на процесора.

Например: присвояване на стойности, събиране и извикване на метод.

Single-Core CPU:

Инструкциите се изпълняват **една по една** в последователен ред.

Няма паралелна обработка – всичко става последователно.
#### Scheduler
Scheduler-ът **не чака** процесорът да се освободи, **а активно управлява нишките**, като:

- **Спира изпълнението на текущата нишка** в произволен момент (дори да не е приключила).

- **Пуска следващата нишка** според вътрешна логика и приоритети.

- Това значи, че когато каже „сега ще се изпълнява `Program.exe`“, може да пусне **само няколко инструкции** и веднага след това да превключи на друга програма (например `chrome.exe`).

Така че:

- **Не се изчаква завършване на нишката**, а се прави **бързо превключване** (context switch).

- Дори ако процесорът е на 100% натоварване, **не значи, че програмата е забила** — просто **други нишки са спрени временно**, за да се изпълни текущата.

- Този процес се случва **много бързо и циклично** на всяко ядро, така че изглежда сякаш всичко работи едновременно.

⏱ **Няма гаранция за ред или продължителност на изпълнение**

- **Не можем да предвидим коя нишка ще приключи първа** — дори ако една задача изглежда кратка, тя **може да бъде отложена** поради натоварването на системата.

- Например: ако знаем, че една операция отнема точно **10ms**, и няма други активни нишки — тя ще се изпълни за 10ms.

- **Но ако машината е натоварена**, scheduler-ът ще прекъсва нашата нишка няколко пъти, за да даде време на други процеси.

- Така общото време на изпълнение ще си остане 10ms, но **ще бъде разпределено във времето**, например:

    - стартира за 2ms

    - после чака, защото друг процес заема CPU

    - после се изпълнява още 3ms

    - и т.н., докато натрупа 10ms изпълнение
        
    - но реално **завършва след 30ms** например

Тоест: **изпълнението е бързо, но не и непрекъснато** – това зависи от натоварването на системата и решенията на scheduler-а.

Scheduler-ът **умишлено превключва между нишките**, за да създаде илюзия за паралелно изпълнение, дори когато има само едно ядро. Целта му не е да изчака дадена програма да свърши, а:

- да **разпредели времето на процесора** между всички активни нишки

- да **предотврати забиване** или блокиране на цялата система от тежка или бавно изпълняваща се програма

- да **гарантира, че всяка нишка получава малко "време на сцената"**

📌 Всяка нишка си изпълнява своята логика и не знае какво става с другите. Но scheduler-ът я прекъсва, за да даде път на друга нишка – това се нарича **preemptive multitasking.**

**Пример за изпълнение на нишки**

Имаме **три програми**: `Program A`, `Program B` и `Program C`.

|Време|CPU времево пространство|
|---|---|
|0ms|Program A (1ms)|
|1ms|Program B (1ms)|
|2ms|Program A (1ms)|
|3ms|Program C (1ms)|
|4ms|Program A (1ms)|
|5ms|Program B (1ms)|
|6ms|Program A (1ms)|
|7ms|Program C (1ms)|
|8ms|Program B (1ms)|
|9ms|Program A (1ms)|

- **Program A**, **Program B** и **Program C** не се изпълняват непрекъснато.

- Scheduler-ът превключва между тях на всеки 1ms.

- Въпреки че всяка програма е започнала изпълнението си, тя ще бъде прекъсната след определено време, за да може другите програми да се изпълняват също.

- Това гарантира, че всички програми имат време да работят върху процесора, без една да блокира останалите.

Това е принципът на **multitasking** и как scheduler-ът се грижи за **балансирано разпределение на ресурсите**.

**Важно:**

- **Една нишка** може да изпълнява части от **множество програми**, но тя може да изпълнява само **една задача по едно време**.

- Ако имаме повече нишки, всяка нишка ще може да изпълнява **една програма или задача** по едно време, но на едно ядро все още няма реален паралелизъм, освен ако не използваме **много ядра**.

Така, с ограничен брой нишки, всяка нишка може да изпълнява **части от различни програми**, но целият процес е **симулиран паралелизъм**, не истински такъв.
### Multi-Tasking
Един компютър може да изпълнява много процеси (приложения) едновременно.

Но всяко ядро на процесора може да изпълнява само **една инструкция наведнъж**.

Паралелизмът (parallelism) се постига чрез scheduler на операционната система. Броят на процесорните ядра не е достатъчен, за да може всяка програма да се изпълнява на отделна нишка едновременно. Затова scheduler-ът разпределя процесорното време между множество нишки, като им дава кратки интервали за изпълнение.

Той дава на всяка нишка малък интервал от време за изпълнение.

Това поведение се нарича **мултитаскинг**.

Колкото повече ядра има процесорът, толкова повече нишки могат да бъдат изпълнявани **истински паралелно**, а не само чрез бързо превключване.
Пример за разпределение на времето в една нишка (на едно ядро):

program.exe chrome.exe winamp.exe system.exe program.exe ...
0  5 ms           10 ms           15 ms           20 ms         25 ms  

Тук всяка програма получава кратък интервал за изпълнение (напр. 5 милисекунди), след което scheduler-ът превключва към следващата. Ако има повече ядра, подобни редове се изпълняват паралелно.
### Threads in CSharp
Нишки в C# могат да се създават чрез класа **`System.Threading.Thread`**.

Конструкторът приема метод (делегат), който да се изпълни в отделна нишка.

```csharp
Thread thread = new Thread(() =>
{
    for (int i = 0; i < 10; i++)
    {
        Console.WriteLine(i);
    }
});
```

Разликата между `Task.Run()` и `System.Threading.Thread` е, че когато използваме `Task.Run()`, **не създаваме нова нишка директно**, а даваме на операционната система и framework-а възможност да преценят дали е необходимо да създадат нова нишка. Ако системата е силно натоварена и няма налични ресурси, може да не бъде създадена нова нишка. Използването на `Task` представлява по-сложен процес, в който framework-ът и операционната система решават най-ефективния начин за изпълнение на задачата, но за нас то работи като асинхронно изпълнение, подобно на нова нишка.

Обаче, когато използваме **`System.Threading.Thread`**, ние **задължаваме framework-а да създаде нова нишка**. Това е по-малко гъвкав подход, при който ние директно изискваме нова нишка, без да оставяме на операционната система да вземе решение за нея.
### `System.Thread`
 **`Start()`** – планира нишката за изпълнение, тоест влиза в scheduler, а той преценява кога къде и как да го пусне -  **тоест не управляваме директно времето** на стартиране. Реалното стартиране се случва, когато scheduler-ът реши, че е време.

**`Join()`** – изчаква нишката да завърши работата си (блокира извикващата нишка, докато приключи).

Пример:

```csharp
Thread primes = new Thread(() =>
{
    PrintPrimesInRange(1, 10000);
});

primes.Start();

Console.WriteLine("Waiting for thread to finish work...");

primes.Join();  // Blocks the main thread until the 'primes' thread completes
```

**`Start()`** стартира новата нишка, която започва да изпълнява кода в делегата (в случая методът `PrintPrimesInRange`).

**`Join()`** блокира главната нишка, докато нишката `primes` не приключи работата си.

**Example:**

```csharp
List<long> numbers = new List<long>();

Thread t = new Thread(() =>
 SumOddNumbers(numbers, 10, 100000000L));
 
t.Start();

Console.WriteLine("What should I do?");

while (true)
{
 string command = Console.ReadLine();
 if (command == "exit") break;
}

t.Join();

void SumOddNumbers(List<long> numbers, long start, long end)
{
    long sum = 0;
    for (long i = start; i <= end; i++)
    {
        if (i % 2 != 0) // Check if the number is odd
        {
            sum += i;
        }
    }
    numbers.Add(sum); // Store the result in the numbers list
    
    Console.WriteLine($"Sum of odd numbers between {start} and {end} is: {sum}");
}
```

В примера се създава нова нишка с `Thread`, която изпълнява метода `SumOddNumbers` за изчисляване на сумата на нечетните числа в даден диапазон. Докато нишката работи, основната нишка може да продължи да приема команди от потребителя. След като потребителят въведе командата `exit`, основната нишка изчаква завършването на фоновата нишка чрез `t.Join()` преди програмата да приключи.
### Thread Stack
Всяка нишка има свой собствен стек  
- Началото (дъното) на стека е методът, от който нишката започва изпълнение.

- Всеки метод (рамка) съхранява локални променливи.

**Стек на нишката**  
...  
**`IsPrime()`**  
**`PrintAllPrimes()`**  
**`Main()`**  
main thread

...  
**`IsValidUrl()`**  
**`DownloadAsync()`**  
background thread
### Thread Race Condition
**Race condition** възниква, когато два или повече нишки имат достъп до споделени данни и се опитват да ги променят едновременно.

**Пример:**

```csharp
List<int> numbers = Enumerable.Range(0, 10000).ToList();
for (int i = 0; i < 4; i++)
{
    new Thread(() =>
    {
        while (numbers.Count > 0)
            numbers.RemoveAt(numbers.Count - 1);
    }).Start();
}
```

В този пример имаме списък от цели числа (`numbers`), и множество нишки се опитват да премахват елементи от него едновременно. Тъй като списъкът (`numbers`) е споделен между нишките, те могат да се намесват една в друга, когато получават достъп и модифицират данните. Това води до **race condition.**

Как може да се случи race condition в този пример:

1. **Споделен ресурс**: Списъкът `numbers` е споделен между всички нишки, като всяка нишка се опитва да изпълни операцията `RemoveAt(numbers.Count - 1)` (премахва последния елемент от списъка).
    
2. **Едновременен достъп**: Множество нишки могат да се опитват да премахнат елементи от списъка едновременно. Когато две нишки едновременно четат стойността на `numbers.Count`, те може да смятат, че премахват последния елемент от списъка, но всъщност могат да модифицират същия елемент или да премахнат по-малко елементи от очакваното.
    
3. **Неопределен резултат**: В резултат на това, елементи могат да бъдат премахвани неправилно или някои елементи може да не бъдат премахнати изобщо, защото нишките не координират правилно достъпа си до споделените данни.
### Thread Safety
Ресурс, който е **потокобезопасен**, може да бъде безопасно достъпен от множество нишки едновременно.

- Ключовата дума `lock` дава достъп само на една нишка по време.

- Предотвратява **race conditions.**

- Блокира всички други нишки, докато заключването не бъде освободено.

```csharp
lock (numbers)
{
    if (numbers.Count == 0) break;
    int lastIndex = numbers.Count - 1;
    numbers.RemoveAt(lastIndex);
}
```

За да избегнем race condition, когато модифицираме споделени данни като списъци, можем да използваме синхронизационни механизми като **заключвания (locks)** или други средства за синхронизация, за да осигурим, че само една нишка може да достъпва споделените данни по едно и също време.

**Използване на заключване (lock):**

```csharp
List<int> numbers = Enumerable.Range(0, 10000).ToList();
object lockObject = new object(); // Lock object

for (int i = 0; i < 4; i++)
{
    new Thread(() =>
    {
        while (true)
        {
            int index;
            lock (lockObject)  // Locking the shared resource
            {
                if (numbers.Count == 0) break;  // Exit the loop if there are no more elements
                index = numbers.Count - 1;
                numbers.RemoveAt(index);  // Remove the last element from the list
            }
        }
    }).Start();
}
```

**Обяснение:**

- **Механизъм за заключване**: `lock (lockObject)` осигурява, че само една нишка може да влезе в критичната секция, където се достъпва и променя споделеният ресурс (`numbers`). Това предотвратява едновременен достъп и модификация на списъка от множество нишки, като по този начин се избягва състоянието на състезание.

- **Безопасност на нишките**: Заключването гарантира, че премахването на елементи от списъка е безопасно за нишките, т.е. няма да се случи едновременен достъп и промяна на списъка.

Чрез използване на синхронизационни механизми като заключвания можем да осигурим безопасен достъп до споделени ресурси в многонишкови среди, като по този начин предотвратяваме race condition.
### Exception Handling
Изключенията в нишки не могат да бъдат уловени извън самата нишка. В примера:

```csharp
try
{
    new Thread(DoWork).Start();
}
catch (Exception ex)
{
    Console.WriteLine("Exception!");
}
```

Този `catch` няма да улови изключението, хвърлено в нишката, защото изключенията не се прехвърлят в основния поток.

**Exception Handling – the Right Way**

```csharp
new Thread(DoWork).Start();

public static void DoWork()
{
    try
    {
        throw new ArgumentNullException();
    }
    catch (Exception ex)
    {
        Console.WriteLine("Exception handled!");
    }
}
```

Изключенията трябва да се обработват вътре в изпълнявания метод(и).
## Tasks in CSharp
Цялата сложност при работа с нишки може да бъде избегната благодарение на **Task** в C#. С **Tasks** печелим **по-голяма абстракция** и **леснота при управление на паралелизъм**, като същевременно запазваме добра производителност и ефективност, без да се налага да се занимаваме с ниско ниво синхронизация или управление на нишки.

**Task** е библиотека в .NET, която прави паралелното програмиране много по-лесно. Тя работи с концепцията **асинхронни операции**, която помага да изпълняваме задачи паралелно, без да се сблъскваме с проблеми като **race conditions** или **заключвания** при достъп до споделени ресурси. Всичко това се управлява автоматично от системата.

С Task библиотеката, **не е нужно да се тревожим за нишките**, защото тя автоматично ги управлява. Можем да се съсредоточим върху бизнес логиката, докато .NET се грижи за създаването, изпълнението и приключването на нишките, както и за синхронизацията им.

**Пример:**

```csharp
public async Task<int> DoSomeWorkAsync()
{
    // This task will be executed asynchronously
    await Task.Delay(2000); // Simulate a delay
    return 42; // The result of the task
}

public async Task RunTaskExample()
{
    int result = await DoSomeWorkAsync(); // Wait for the task to complete
    Console.WriteLine($"Result: {result}");
}
```

Task и `async/await`

**Task** и `async/await` pattern-a са взаимно свързани и представляват начин за обработка на **асинхронни задачи**. В C# когато дефинираме метод, който връща **Task** (или `Task<T>` за стойност), ние всъщност казваме на компилатора, че този метод ще изпълни нещо, което ще отнеме време, но няма да блокира текущия поток. След това можем да използваме ключовите думи `async` и `await` за да управляваме процеса.

**Ключови предимства на Task:**

1. **Лесно управление на нишките:** Task библиотеката абстрахира управлението на нишките. Ние не трябва да се притесняваме за създаване, стартиране или спиране на нишки.

2. **Паралелизъм без сложности:** Task управлява race conditions и други проблеми, които възникват при многопоточните програми.

3. **Гъвкавост**: Task може да бъде изпълняван асинхронно, което позволява на нашето приложение да извършва други задачи, докато чака дадена операция да приключи.

В **ASP.NET** всичко свързано с асинхронност се прави с помощта на **Task**. Например при работа с бази данни, мрежови заявки или други дълготрайни операции, вместо да блокираме основната нишка (както бихме направили с `Thread`), използваме **`async`** и **`await`**, за да стартираме асинхронни задачи, които позволяват на нашия сървър да обслужва повече заявки едновременно.

Пример с асинхронна работа със сървърна заявка: _(може да се добави пример по желание)_

```csharp
public async Task<IActionResult> GetDataAsync()
{
    var data = await FetchDataFromDatabaseAsync();
    return View(data);
}

private async Task<List<Data>> FetchDataFromDatabaseAsync()
{
    // Simulating asynchronous data retrieval from a database
    await Task.Delay(1000); // simulating delay
    return new List<Data> { new Data() };
}
```

**Заключение**

Използването на **Task** ни предоставя силни инструменти за паралелно програмиране в .NET, които са лесни за използване и облекчават много от задачите, свързани с управление на нишки. Същевременно, не е нужно да се справяме с всички **сложни детайли** и проблеми на многопоточността, тъй като Task автоматично ги решава.

- Task е високо ниво представяне на паралелна работа.

- Изпълнява се паралелно с главната нишка.

- Може да не ползва нова нишка (решава CLR - Common Language Runtime).

- Предлага множество операции:  
	- Създаване, стартиране и връщане на резултат.

	- Продължаване с друга задача (верижно изпълнение).

	- Коректно обработване на изключения.

	- Отчитане на прогрес/състояние.
### Creating Tasks
Създаването на задачи може да се направи по няколко начина: 

- Инициализиране на нов обект

```csharp
Task task = new Task(() => { Console.WriteLine(""); });
```

- `Task.Run()`

```csharp
// Using the static method Run()
Task.Run(() => TraverseMatrix());
```

- `Task.Factory.StartNew()` - позволява допълнителна персонализация на задачата.

```csharp
Task.Factory.StartNew(() => CopyFileContents("got-s03ep1.avi"), TaskCreationOptions.LongRunning)
```
### Generic Tasks
`Task` не връща резултат, защото е тип `void`. Ако искаме да върнем резултат, трябва да използваме **generic task**.

`Task<T>` е task, който ще върне резултат в бъдеще.

```csharp
Task<long> task = Task<long>.Run(() =>
{
    long sum = 0;
    for (int i = 0; i < 10000; i++) sum += i;
    return sum;
});

Console.WriteLine(task.Result); // Blocks the calling thread until the task returns a result.
```

Резултатът ще бъде от тип `Task<T>` и може да се достъпи чрез променливата с `.Result`, който ще изчака таска да приключи, преди да изпълни командата. Когато използваме `.Result`, извикващата нишка ще изчака получаването на резултата, което я блокира, докато задачата не завърши.
### Exception Handling
Изключенията, които са възникнали в тялото на един task, могат да бъдат уловени и обработени извън него.

**Обработка на изключения в задачи:**

```csharp
var task = SliceAsync(VideoPath, DestinationPath, 5);
try
{
    task.Wait();
}
catch (AggregateException ex)
{
    // Handle exception...
}
```

Можем да използваме **`AggregateException`**, за да обгърнете всички изключения, хвърлени от различни нишки.
## Tasks with async / await
Ключовите думи **async** и **await** винаги се използват заедно.
### async
Подсказва на компилатора, че методът може да работи паралелно.

Не прави методът да работи асинхронно (това прави **await**).

```csharp
static async void SliceFileAsync(string file, int parts)
```

Казва на компилатора "този метод може да изчака ресурс или операция".

Ако започне да чака, се връща към извикващия метод.

Когато чакането приключи, се връща към извикания метод.
### await
**await** се използва само в метод, който има ключовата дума **async**. 

Това е мястото, където нашия метод трябва да изчака резултата от асинхронната операция. Стигайки до **await** нишката е свободна да се върне едно ниво надолу и да изпълнява други неща и ако стигне до дъното на стека, ще бъде свободен за изпозлване от някой друг.
В момента в който имаме върнат резултат, нишката ще отиде там и ще продължи изпълнението, но докато е бил освободен, някой друг е позлвал този ресурс. 

Това е мястото, където методът ни трябва да изчака резултата от асинхронната операция. Стигайки до **await**, нишката е свободна да се върне едно ниво назад и да изпълнява други задачи. Ако достигне дъното на стека, тя става свободна за използване от друг процес.
В момента, в който бъде върнат резултатът, същата или друга налична нишка ще поеме изпълнението оттам, откъдето е било спряно. През времето, докато е била освободена, **друга операция може да е използвала тази нишка**.

Запазва контекста в state machine (машина на състоянията).

Маркира чакането на ресурс (задача, която трябва да приключи).

Ресурсът трябва да бъде от тип **`Task<T>`**.

Връща резултат от тип **T** от **`Task<T>`**, когато завърши, но крайния резултат ще бъде `<T>`, когато сме ползвали **await**.

```csharp
await DownloadStringAsync("https://softuni.org"); // Returns Task<string>
```

**async / await Example:**

```csharp
static void Main()
{
    DownloadFileAsync(FileUrl, "book.pdf"); // After the method is over the calling thread gets back to the calling method
    // Do some other work
}

static async void DownloadFileAsync(string url, string fileName)
{
    Console.WriteLine("Downloading...");
    // The calling thread exits the method on await
    await Task.Run(() =>
    {
        // Download the file
    });
    
    Console.WriteLine("Download successful."); // When the waiting is over, the calling thread proceeds with method execution
}
```

**Summary:**

В ASP.NET приложението ни всички методи трябва да бъдат асинхронни, с едно единствено изключение — ако методът не прави нищо друго, освен да върне `View` примерно, тогава може да остане синхронен.

В момента, в който има обръщение към база данни или друг външен ресурс, методът **задължително трябва да бъде асинхронен**. Microsoft препоръчва всяка операция, която очакваме да отнеме повече от **50 милисекунди**, да бъде реализирана асинхронно.

На практика това означава, че **всяка операция, която достъпва външен ресурс**, трябва да бъде асинхронна — независимо дали става дума за база данни, файлова система, уеб услуга или нещо друго извън текущия процес. 

Реално кодът изглежда като обикновен синхронен код, но с предимството, че даваме възможност на фреймуърка да го изпълни асинхронно. Така позволяваме ефективно **споделяне на нишки като ресурс**, което води до **значително по-висока производителност и по-добър scaling** на приложението ни.
# Misc
# ChatGPT
## 🧵 What is a thread
A **thread** is the smallest unit of execution in a program. You can think of it as a **separate worker** doing a specific task. All threads within the same program **share the same memory (resources)**, but each thread has its own **execution context** — meaning it knows what it’s doing and where it left off.

🧠 **What is the main thread?**

When a program starts, it begins with a **main thread** by default.  
If you don’t create any additional threads, **everything runs sequentially inside that main thread**.

🤝 **How do threads correlate or interact?**

- **They share resources**: All threads have access to the same memory — variables, files, databases.

- **They can block each other**, if two threads try to access the same resource at the same time without coordination → this leads to issues like race conditions or deadlocks.

- **Synchronization** is needed when threads need to communicate or coordinate — using tools like `lock`, `mutex`, `await`, `join`, `signal`, etc.

📌 **What’s the difference between the main thread and other threads?**

|**Main Thread**|**Other (Secondary) Threads**|
|---|---|
|Starts automatically|Created manually or via libraries|
|Runs the main program code|Handle specific parallel tasks|
|If it finishes, the program ends|Can end independently|
|Shouldn't be blocked for long tasks|Help offload work from the main thread|

🧠 **Analogy:**

Imagine the main thread is a **receptionist** in an office.  
If they have to do everything — answer calls, print documents, make coffee — productivity drops.  
But if you bring in **helpers (threads)** for certain tasks, the receptionist (main thread) can focus on the most important things.
## The Role of `await` in Thread Management and Concurrency
If we don’t use the `await` pattern, there will be no difference as long as there are threads available. Let’s say there are 8 threads available and only 8 users hit the controller. In this case, even if their operations take a long time and we don’t release the threads with the `await` pattern, there will be no difference since no other users try to reach the controller. The `await` pattern will only be useful if another user hits the controller while all threads are busy. Thanks to `await`, the threads will be released, allowing the server to handle more user requests, is this correct?

**ChatGPT said:**

Yes, exactly! You've got it right. Let's break this down further to make sure everything is clear.

**Without `await`:**

If you don't use the `await` pattern and just execute everything synchronously, the following happens:

- When a **User hits the controller**, a thread from the **thread pool** (let's say you have 8 threads) is allocated to handle that request.

- **If the operation takes a long time** (e.g., a database call or some lengthy computation), the thread will be **blocked** until that operation is completed.

- If **only 8 users** hit the controller, and there are 8 threads available, then **each request** gets its own thread from the pool and each will execute fully on that thread without interference.

- Since no new requests are coming in while all threads are used, there is **no real "concurrency" issue** — each thread is just serving its respective user request one after the other.

So, in this case, **there is no issue** — each thread is busy, and everything runs as expected for each request.

**With `await`:**

The **`await`** pattern helps in situations where there are **more users** or long-running asynchronous operations, and it helps **free up threads** during I/O-bound operations (e.g., database calls, HTTP requests, etc.).

- When you use `await`, the thread **doesn't stay blocked** while waiting for the operation to complete.

- When a request hits the controller, it gets a thread from the pool.

- If that operation involves **waiting for something** (like a database query or calling an external API), the thread is **released back** to the pool and can be reused for other tasks (such as serving other requests).

- If another user hits the controller, **and threads are available** (or they are freed up by the `await` pattern), the server can use those threads to handle the new request **immediately**.

**The key difference**:

- **Without `await`**: The threads are **blocked** and not available for other requests until the long operation finishes.

- **With `await`**: Threads are **freed up** during waiting, so they can be reused to handle new requests, improving overall efficiency, especially when there are many concurrent requests.

**What happens when all threads are used?**

- **Without `await`**: If all 8 threads are used up (because all 8 users are making long-running requests), any **new user requests** will have to wait until a thread becomes available.

- **With `await`**: When `await` is used, and there are more than 8 requests coming in, the threads will be **freed up** once the I/O-bound tasks (like database calls) are awaiting, which means **more requests** can be processed simultaneously, without blocking all threads.

**Summary:**

- **Without `await`**, if you only have 8 threads and 8 requests, there is no immediate problem — but **if more users come in** and all threads are busy, they'll be blocked until threads are free.

- **With `await`**, threads are released during I/O operations, and **other requests can be processed concurrently** if needed, making the system more responsive, especially when there are a lot of concurrent requests or long-running tasks.

In essence, the **`await` pattern** shines in scenarios with **high concurrency** or **waiting operations** because it maximizes the use of available threads, keeping the server responsive.
## What Happens to the Main Thread During `Task.Run()`
When `Task.Run()` is called, the **main thread** (or whichever thread calls `Task.Run`) does not block waiting for the task inside `Task.Run()` to finish. Instead, the main thread:

1. **Schedules the task to run on a separate thread** (from the ThreadPool).

2. **Continues to execute** the rest of the program without waiting for the task in `Task.Run()` to complete.

**Step-by-Step Flow:**

1. **Main thread starts execution** and calls `Task.Run()`:

```csharp
await Task.Run(() =>
{
    Console.WriteLine($"[Task.Run] Running - Thread ID: {Thread.CurrentThread.ManagedThreadId}");
    Thread.Sleep(1000); // Simulate work
});
```

1. **Main thread schedules the task** to run on a new thread from the `ThreadPool`. This **new thread** starts immediately and executes the code inside `Task.Run()` (the task).

2. **Main thread continues executing** the next lines of code after `Task.Run()` without waiting for the task inside `Task.Run()` to finish. If the main thread has more code after `Task.Run()`, it will execute it **immediately**, allowing the program to do other work.

3. When the task inside `Task.Run()` finishes (after the `Thread.Sleep(1000)`), control is returned to the main thread, but only if you are **waiting** for the task, such as using `await` or `Task.Wait()`.

**Visualizing the Flow:**

- **Main thread:** Runs `Task.Run()`, hands off the task to a new thread, and continues immediately with the next instruction.

- **New thread (`ThreadPool` thread):** Runs the code inside `Task.Run()`.

📑 **Example:**

```csharp
using System;
using System.Threading;
using System.Threading.Tasks;

class Program
{
    static async Task Main()
    {
        Console.WriteLine($"Main thread starts. Thread ID: {Thread.CurrentThread.ManagedThreadId}");

        await Task.Run(() =>
        {
            Console.WriteLine($"[Task.Run] Running on thread ID: {Thread.CurrentThread.ManagedThreadId}");
            Thread.Sleep(1000);  // Simulate work
        });

        Console.WriteLine("Main thread continues after Task.Run.");
        Console.WriteLine($"Main thread ends. Thread ID: {Thread.CurrentThread.ManagedThreadId}");
    }
}
```

🧮 **Expected Output:**

```
Main thread starts. Thread ID: 1
[Task.Run] Running on thread ID: 4  // New thread from ThreadPool
Main thread continues after Task.Run.
Main thread ends. Thread ID: 1
```

**What Happens:**

- The **main thread** (thread ID `1`) starts and immediately calls `Task.Run()`, sending work to a **new thread** from the ThreadPool (`thread ID 4`).

- While `Task.Run()` runs on the new thread, the **main thread** continues and **does not wait** for the task to complete. It outputs `Main thread continues after Task.Run.` and ends.

- The main thread does not block, and it finishes its execution while the task continues to run on the separate thread.

⚡ **Key Points:**

- The **main thread** does **not wait** for the task in `Task.Run()` to complete unless you specifically tell it to wait using `await` or `Task.Wait()`.

- If you **don't `await`** the task, the main thread will **immediately continue** with the next code after calling `Task.Run()`, even if the task is still running.

- If you **`await`** the task, the main thread will pause at `await` until the task finishes, but it will not block — other work can happen on the main thread during that time.
## Only One Thread Available For Two Users
What happens if we have user A and user B and both hit a controller and there is only one thread available?

**ChatGPT said:**

Perfect — let's imagine **only one thread** exists (say, in a simplified web server) and both **User A** and **User B** hit the same controller **at roughly the same time**, and the controller uses `await`.

**🧩 Controller code (simplified):**

```csharp
public async Task<IActionResult> GetData()
{
    Console.WriteLine("Start");

    await Task.Delay(1000); // Simulate DB or API

    Console.WriteLine("End");
    return Ok();
}
```

🧠 **What happens with just one thread**:

1. User A makes a request:

- Server starts `GetData()` on the **main thread**.

- It prints `"Start"`.

- Hits `await Task.Delay(1000)` → the method **pauses**.

- The **main thread is freed**.

- Timer starts in the background (doesn't need a thread).

2. User B makes a request (while User A is paused):

- The main thread is **free**, so it handles **User B**'s `GetData()`.

- It prints `"Start"`.

- Also hits `await Task.Delay(1000)` → **User B**'s method also **pauses**.

- Now both User A and User B are **waiting** for their delays to finish.

- The thread is still **not blocked**.

**3. After 1 second:**

- **User A**'s delay finishes.

- Its continuation (`Console.WriteLine("End")`) is **queued** to the main thread.

- The main thread resumes User A’s code, prints `"End"`, returns `Ok()`.

**4. Then:**

- **User B**'s delay finishes too (nearly at the same time).

- Its continuation is also queued.

- After User A finishes, the thread moves to **User B**'s continuation, prints `"End"`, and returns `Ok()`.

**⏸ Summary (with only one thread):**

|Time|Thread is doing|Notes|
|---|---|---|
|0 ms|User A starts, prints "Start"|Thread is busy with User A|
|~10 ms|User A hits `await`, thread freed|User A is waiting (via timer)|
|~11 ms|User B starts, prints "Start"|Thread now runs User B|
|~20 ms|User B hits `await`, thread freed|Both A and B are now "paused"|
|1000 ms|User A's delay completes|User A’s code resumes|
|1001 ms|Prints "End" for User A||
|1002 ms|User B's delay completes|User B resumes after A|
|1003 ms|Prints "End" for User B||

**✅ Key Takeaways:**

- Even with just **one thread**, `await` allows multiple requests to **coexist** efficiently.

- The thread **never blocks** on I/O — it always moves forward.

- Each request resumes only when its awaited operation completes and the thread is available.

- Execution is **not truly parallel**, but it's **non-blocking and concurrent**.

**You said:**

What if the user's A database operation finishes before the thread reaches the user's B await database operation? Will it immediately switch back to user A, or will it reach the await operation and then switch back to user A? If the latter, this means there was a time when the operation for user A was finished, but they had to wait for the ongoing thread processing of user B?

**ChatGPT said:**

Excellent and **very insightful** question.

Let’s walk through your exact scenario in a single-threaded environment where two users (User A and User B) hit the same controller. The controller awaits a database call (simulated as `Task.Delay(1000)` for simplicity).

🔍 **Scenario Breakdown:**

We assume:

- Only **one thread** (the main thread).

- `async/await` is used (non-blocking).

- The **awaited operation is I/O-bound** (e.g., DB call, network call), so it doesn't need a thread to wait.

👣 S**tep-by-step Timeline**

Let’s say:

1. **User A** starts at time `0ms`

2. **User B** starts at time `200ms`

3. The DB operation for **User A finishes at 1000ms**

4. The DB operation for **User B finishes at 1200ms`


Here’s what happens:

|Time|What Happens|
|---|---|
|0ms|User A starts. Hits `await dbCall`. Control returns. Main thread is **free**.|
|200ms|User B starts. Hits `await dbCall`. Control returns. Now both A and B are **awaiting**.|
|1000ms|User A's DB operation finishes. Its continuation is **queued**. But thread is **busy with B**?|
|1000ms - 1200ms|**If** the thread is **currently processing B’s code before reaching await**, it must **finish up to the await**.|
|~1200ms|Then the thread picks up A’s continuation. Executes A’s `after await` code.|
|~1300ms|Then picks up B’s continuation. Executes B’s `after await` code.|

🧠 **So, to your question:**

> **If User A’s DB operation finishes before User B even reaches the `await`, does the thread switch back to User A immediately?**

❌ **No.**

It **does not preempt** execution.

- The thread is **not interrupted**.

- Even if User A’s result is ready, it has to **wait in the continuation queue**.

- The thread finishes **what it’s currently doing** (e.g., processing User B **up to the `await`**).

- Only then will it pick the next ready continuation (like User A’s).

✅ **Conclusion:**

Yes, **User A can finish waiting earlier**, **but still wait longer** to resume execution, **because the single thread was busy** running synchronous code for User B.

This is **not wasteful**, but just a natural limitation of **single-threaded, cooperative concurrency**.

In this particular scenario, with `await`, User A might wait a little longer because the thread doesn't block and is free to process other tasks (like User B’s operation) while User A’s task is still waiting for an async operation to complete.

However, the key advantage is that once User A's task is done, subsequent users (like User B) will experience shorter wait times because the thread can switch between tasks efficiently.

This trade-off — where User A may wait slightly longer, but all subsequent users benefit from shorter wait times — is one of the core advantages of using asynchronous programming. It improves overall throughput by allowing the thread to handle more tasks concurrently.
## Similarities between C# `async/await` and JavaScript's Event Loop

1. **`await` pauses execution**:

    - In both C# and JavaScript, `await` **does not block the thread**.

    - It **schedules the continuation** (the rest of the function) to run **later**, once the awaited task is complete.

2. **Continuations go to a queue**:

    - In C#, it's the **task scheduler or synchronization context**.

    - In JavaScript, it's the **microtask queue** (for promises).

    - In both cases, even if the task completes **immediately**, the continuation goes to the back of the queue.

3. **The thread/loop runs one task at a time**:

    - Both systems rely on a **single-threaded model** (C# can be multithreaded, but async/await doesn't require it).

    - Only **one continuation is executed at a time**, in the order they were scheduled.

🧠 **Key Insight:**

In both JavaScript and C#, the "magic" of `await` is not in starting new threads, but in **delaying the continuation** and **not blocking** the current thread or loop.
## Hardware vs. Software Threads
**Hardware threads** (from CPU cores):

- Limited by physical CPU capabilities (e.g., 16 cores × 2 = 32 hardware threads).

- These are the **actual parallel execution lanes**.

✅ **Software threads** (created by your application):

- .NET (and other runtimes) can create **many more software threads** than hardware threads.

- These threads are **managed by the OS scheduler**.

- The OS time-slices them — meaning it switches between them rapidly on the same hardware thread, not literal simultaneous execution.

🧠 **Example:**

Your server might have:

- **32 logical cores**

- But your ASP.NET app can spawn **hundreds of concurrent software threads.**

They won’t all run _at the exact same moment_, but the OS schedules them **as fast as possible**, making it seem concurrent.

So:  
🗣️ When we say “hundreds of threads,” we mean **many tasks can be handled concurrently**, not that the CPU is physically doing 100+ things at once.
## `await Task.Run()`
Is `await Task.Run()` useful when we want to ensure that the main thread isn't blocked by resource-intensive work, allowing us to protect the main thread and wait for another thread to handle the task?

**ChatGPT said:**

Exactly! You’ve got it right. Using `await Task.Run()` is particularly useful in scenarios where you have limited threads (e.g., only one thread left or you're managing a thread pool with a set number of threads), and you want to **protect your main thread** from being blocked by resource-intensive work.

Here's why:

1. **Protecting the Main Thread**:

    - Without `await Task.Run()`, if your main thread is doing some **resource-intensive work**, it will **block** and be **unavailable** to handle other tasks or incoming requests.

    - By using `await Task.Run()`, you **offload** that work to a **background thread**, so the main thread doesn’t get bogged down. The main thread can keep handling other incoming requests (or other tasks) while the background thread works on the CPU-bound task.

2. **Handling Limited Threads**:

    - Imagine you have only **one main thread** in a web application, or you’re working with a **small thread pool**. If the main thread is stuck waiting on a task, no other work can be done on that thread.

    - By using `await Task.Run()`, you can **free up the main thread** so it can be used for other operations. The CPU-intensive work will be handled by another thread (from the thread pool), meaning the main thread isn't wasted.

3. **When a Background Thread is Available**:

    - When you call `Task.Run()`, it schedules the task to be run on a **background thread**.

    - If a background thread is **free**, it will start immediately. If all background threads are busy, it will wait until one becomes available.

    - While this happens, the **main thread** is not blocked and can continue processing other requests or tasks.

**Use Case Example:**

If your web server or application is handling HTTP requests from multiple users and the tasks involved are **CPU-bound** (e.g., data processing, image manipulation), you might want to make sure that:

- The **main thread** is available to **serve other user requests**.

- CPU-intensive tasks like data processing are **offloaded to a separate thread** so they don’t block the main thread.


This makes your application more responsive and can handle more users effectively.

**Flow:**

1. **Main thread** receives a request (e.g., User A makes a GET request).

2. The **main thread** starts processing, but hits `await Task.Run()`, offloading the **CPU-bound task** to a **background thread**.

3. While the background thread is working, the **main thread** is free and can handle **other requests** (e.g., User B's request).

4. Once the background thread finishes the CPU-intensive task, the **main thread** resumes execution, continuing after `await` to return the response to the client.

**In Code:**

```csharp
public async Task<IActionResult> HandleRequestAsync()
{
    // The main thread is freed up while the background thread processes the task.
    await Task.Run(() => DoCpuIntensiveWork());

    // Once the background task finishes, the main thread resumes.
    return Ok("Request completed!");
}

public void DoCpuIntensiveWork()
{
    // Simulating CPU-intensive operation
    Thread.Sleep(5000);  // Placeholder for actual CPU work
}
```

In this case:

- **Main thread**: Handles the HTTP request and immediately hands off the CPU-bound work to a background thread using `await Task.Run()`.

- **Background thread**: Runs the CPU-intensive work (like `Thread.Sleep()` in this example).

- **Main thread**: Is free to process other tasks while the background thread is busy.

**Conclusion:**

By using `await Task.Run()`, you ensure that your **main thread is protected** from being blocked by CPU-intensive work. This is especially helpful in environments where you have a limited number of threads (e.g., a thread pool) and want to maximize throughput without waiting for threads to become free.

**You said:**

Why not use only `run()` with `await`?

**ChatGPT said:**

That's a great question! Let's break down why we use **`Task.Run()`** _and_ **`await`** together, rather than just using **`Task.Run()`** alone.

1. **`Task.Run()`**:

- **Purpose**: It schedules a task to be run on a **separate thread** (typically from the thread pool).

- **When to use**: You use `Task.Run()` when you have a **CPU-bound operation** that you don’t want to block the main thread with. It ensures the work is offloaded to another thread, freeing up the main thread for other tasks.

However, using **`Task.Run()`** by itself doesn't allow your application to "pause" and wait for the result of the CPU-bound task. The task will execute in the background, but you don't get any asynchronous behavior — you still have to wait for it in a blocking manner (i.e., the thread will block while waiting for the result of that CPU task).

2. **`await`**:

- **Purpose**: It tells the **asynchronous code** to "pause" the execution of the method until the task is complete.

- **When to use**: You use `await` when you want to **pause** the method execution and **not block the main thread**. `await` is useful primarily for **I/O-bound operations** (like waiting for database queries or HTTP requests), because it allows other requests to be handled in the meantime.

Why Use Both (`Task.Run()` + `await`)?

1. **Asynchronous Execution**:

    - Using **`Task.Run()`** on a CPU-bound operation ensures that the work happens on a separate thread, not blocking the main thread.
    
    - **`await`** allows the method to **pause** without blocking the calling thread. The execution flow of the method can return control to the thread pool while waiting for the task to complete, thus **avoiding blocking**.

2. **Main Thread and Request Handling**:

    - If you just use **`Task.Run()`**, the CPU-bound task will execute on a separate thread, but you won’t be able to **pause** the execution of the method to handle other incoming requests.

    - By using **`await Task.Run()`**, the thread is released back to the thread pool while the background work happens. This is important in web server scenarios (like **ASP.NET Core**), where you need to keep threads available for other incoming requests.

**Example Without `await`:**

```csharp
public IActionResult HandleRequest()
{
    var result = Task.Run(() => PerformHeavyCalculation()).Result; // Blocking operation
    return Ok(result);
}
```

- Here, the `Result` property will **block** the calling thread while the task is running.

- Even though `Task.Run()` ensures the heavy work happens on a separate thread, the main thread is still blocked until the task finishes.

**Example With `await`:**

```csharp
public async Task<IActionResult> HandleRequest()
{
    var result = await Task.Run(() => PerformHeavyCalculation()); // Non-blocking
    return Ok(result);
}
```

- Here, the **`await`** ensures the calling thread isn’t blocked while waiting for the result, and the thread is free to handle other requests.

- The `await` pauses the method and frees up the main thread, which is important in web environments like ASP.NET Core, where you might have multiple users and limited threads available.

**Summary:**

- **`Task.Run()`** ensures the CPU-bound work is executed on a separate thread.

- **`await`** ensures that the main thread is **not blocked** while waiting for the task to complete, allowing other operations to run concurrently.

- **Together**, they enable non-blocking behavior for resource-intensive tasks, freeing up the main thread for other requests, especially in environments like **ASP.NET Core**.

Without `await`, you’d end up blocking your threads and limiting the ability to process concurrent requests. The combination of both allows you to make your code **asynchronous** and **efficient**.

**You said:**

Another key advantage of using `await` in combination with `Task.Run()` is that it allows us to use the result of the returned task after it finishes. Without `await`, if the main thread continues execution before the task completes, any attempt to access the result later may cause an error.

**ChatGPT said:**

Exactly! You've highlighted a key advantage of using **`await`** alongside **`Task.Run()`**. Let's break this down:

Key Advantages of Using `await Task.Run()`:

1. **Releasing the Thread**:

    - As you mentioned, when you use **`await Task.Run()`**, the main thread is **released back to the thread pool** while the background task executes. This is especially crucial in web server scenarios like **ASP.NET Core**, where you want to maximize the number of requests your server can handle without blocking threads. If you don’t release the thread, you might exhaust the available threads in the thread pool, leading to a poor user experience.
  
2. **Avoiding Errors When Accessing Results**:

    - Another critical advantage, as you've pointed out, is that **`await`** ensures that the method **pauses** and **doesn’t continue** until the background task has completed and returned its result. This is particularly useful when you need to use the result of the task **immediately after it finishes**.


    If you don’t use **`await`**, your code would continue executing, potentially accessing the result of the task **before it has completed**. This leads to errors, such as **`NullReferenceException`**, **`InvalidOperationException`**, or others, because the result might not be available when you try to use it.

**Example:**

**Without `await` (Problematic Code):**

```csharp
public IActionResult HandleRequest()
{
    var task = Task.Run(() => PerformHeavyCalculation()); // Starts the task
    var result = task.Result;  // Blocks the thread here
    return Ok(result);  // Potential error if task isn't completed yet
}
```

In this code, the thread might **block** while waiting for `task.Result`, and if the task hasn't completed yet, accessing the result could lead to issues, especially in more complex cases (e.g., asynchronous I/O operations).

**With `await` (Safe and Proper):**

```csharp
public async Task<IActionResult> HandleRequest()
{
    var result = await Task.Run(() => PerformHeavyCalculation());  // Awaits completion
    return Ok(result);  // Result is guaranteed to be available after await
}
```

In this case, the method **waits** for `PerformHeavyCalculation()` to finish and then returns the result. The `await` ensures that the main thread isn’t blocked unnecessarily, and once the task completes, the result can be used safely without errors.

**Summary:**

- **Using `await`** with `Task.Run()` allows your code to **pause execution** and **safely wait** for the result of a background task, without blocking the main thread.

- Without `await`, if the result is needed immediately after the task is run, you could face errors due to the task not being completed, as the main thread continues execution without waiting for the task to finish.

- **`await`** makes it easier to manage **asynchronous code**, and **ensures correctness** by ensuring that the task has completed before attempting to access its result.

So yes, **`await`** makes sure that the result is available when needed, preventing potential runtime errors when the task isn't yet completed.

**You said:**

But if there isn't a second thread available and we dont use `await`, the resource-intensive task will not start, but the main thread will continue executing the method and eventually finish before the resource-intensive task completes. This means that if the result of the task is not needed later in the method, the main thread will simply complete the method and be free to handle incoming requests?

**ChatGPT said:**

You're absolutely correct in pointing out a nuance in how the application behaves when there is only one thread available.

Let’s break this down:

1. **No Second Thread in the Pool**:

    - If **only one thread is available** in the pool, and the main thread is busy executing the code, the **resource-intensive task** initiated via **`Task.Run()`** will not start immediately because there are no other threads available to process it. The task is effectively **queued** until a thread becomes available.

    - Meanwhile, the main thread **will continue** executing any remaining code, possibly completing the method, depending on how much work is left to do after starting the task.

2. **Main Thread Finishes Before Task**:

    - If the resource-intensive task is **non-blocking** (e.g., it just starts and doesn't require immediate interaction), the main thread can continue executing, potentially completing the method and freeing itself up for other requests.

    - The main thread doesn’t need to **wait** for the result of the task if the result is **not used** below, meaning there’s no actual deadlock or freeze. The main thread is free to complete the method and return to the thread pool.

3. **Potential Issue**:

    - If **you need the result** of the background task in the same method and don’t `await` it, the application could encounter **problems later**, as the result will not be available when needed (this is the point where you would run into issues like accessing an incomplete task result).

    - If the task is CPU-bound and the main thread is the only one available, you’re just not utilizing multi-threading. In this case, you'd want to **protect** the main thread from becoming blocked (so it can handle more incoming requests).

**Potential Deadlock and Freezing Misconception**:

- **Deadlock** in this scenario isn’t very likely if you're not waiting on the result of the background task. The **main thread** will finish its execution and return to the pool, while the **background task** remains in the queue until it gets processed.

- The deadlock you mentioned in the case of **`await Task.Run()` without await** typically happens when the **main thread waits for the task’s result synchronously** (for example, with `.Result` or `.Wait()`), and **if no threads are available** to run the task, you could get into a deadlock.


So, your understanding is correct:

- If the main thread doesn't **need the result** of the task, and there is only one thread available, the main thread will **continue** and complete the method while the task remains in the queue.

- There's no "freeze" because the method can complete without waiting for the resource-intensive task, as long as the result of that task is **not used** further in the method.

Example:

If you're not awaiting the result of the resource-intensive task, like this:

```csharp
public IActionResult HandleRequest()
{
    Task.Run(() => PerformHeavyCalculation());  // Starts a resource-intensive task
    // Main thread continues to execute other code
    return Ok();  // Main thread finishes, task continues in the background
}
```

Here, the main thread doesn't wait for `PerformHeavyCalculation` to complete. It will return the response immediately, and the task will continue running in the background (assuming a thread becomes available).

So **no deadlock** will occur, and **no freeze** will happen. The only issue might arise if **you expect a result** from the task in the same method. If the task doesn’t finish before you attempt to use its result, you could encounter issues.

**You said:**

How will this work? Let's say the main thread finishes the `HandleRequest` method, and after it's completed, another thread becomes available. Will it start executing the `PerformHeavyCalculation` method, or will it be aborted since the main method has already finished?

**ChatGPT said:**

Great follow-up! Let's walk through this situation carefully:

**Scenario Breakdown:**

1. **Main Thread Completes `HandleRequest()`**:

    - The main thread starts executing the `HandleRequest` method.

    - It runs `Task.Run(() => PerformHeavyCalculation())` to start the `PerformHeavyCalculation` task, but **does not await** it. This means it doesn't block on waiting for the task to finish.

    - The main thread then completes the method and exits, returning the response (`Ok()`).

2. **Task in the Queue**:

    - Since the task (`PerformHeavyCalculation()`) was started with `Task.Run()`, it is now in the **queue of tasks waiting to be executed**. The task itself is **asynchronous** and doesn't run immediately unless a thread becomes available to process it.

3. **Thread Becomes Available**:

    - After the main thread finishes its execution (completing the `HandleRequest()` method), another thread from the **thread pool** becomes available.

    - The **task is not aborted**. Instead, once a thread is free, it will pick up the `PerformHeavyCalculation()` task and begin executing it.

**Key Points:**

- The task that was started by `Task.Run()` will **not be aborted** when the main thread finishes executing the `HandleRequest()` method.

- Even though the main thread finishes and returns the response, **the background task (the one you ran with `Task.Run()`) will continue execution** as long as a thread is available to execute it.

- The **main thread's completion** of `HandleRequest()` **does not affect the background task**. Once a thread is available, it will continue executing the task that was queued.

🧠**Important Distinction:**

- **In ASP.NET** (e.g., controller methods like `HandleRequest()`), the process **stays alive** long after a single method returns. So background tasks from `Task.Run()` **will usually continue**.
    
- **In console apps**, the process can end as soon as the last foreground thread ends — unless you're explicitly holding it open.

**Example Flow:**

1. **Request hits the controller**: Main thread starts handling the request.

2. **Task is started with `Task.Run()`**: Background task (`PerformHeavyCalculation()`) is queued.

3. **Main thread finishes**: The main thread completes the method and returns a response to the client.

4. **Another thread becomes available**: A free thread picks up the queued background task (`PerformHeavyCalculation()`).

5. **Background task execution**: The task executes on the available thread, even though the main thread has already completed and returned the response.

So, the task does **not get aborted** just because the main method finishes. The background task will continue executing once a thread is available from the thread pool.
### `Task.Run()` With and Without `await` Example
Consider the following example:

```csharp
class Program
{
    static async Task Main()
    {
        Task.Run(() => ParallelThread());

        for (int i = 0; i <= 100; i++)
        {
            Console.WriteLine($"Main thread in for loop, i = {i}");
        }

        Console.WriteLine("Main thread finishes.");
    }

    static void ParallelThread()
    {
        for (int i = 0; i <= 100; i++)
        {
            Console.WriteLine($"Parallel thread in for loop, i = {i}.");
        }

        Console.WriteLine("Parallel thread finishes.");
    }
}
```

✅ **Without `await`**

```csharp
Task.Run(() => ParallelThread());
```

- The **parallel thread starts**, but `Main` **does not wait** for it to finish.
    
- The main thread continues running its `for` loop independently.
    
- Both threads run **in parallel**, and you'll see **interleaved output** in the console.

✅ **With `await`**

```csharp
await Task.Run(() => ParallelThread());
```

- The **parallel thread starts**, and `Main` **waits** for it to complete before continuing.
    
- The `for` loop in `Main` runs **after** the parallel thread finishes (if placed after the `await`).
    
- Ensures the background work **completes fully** before `Main` proceeds or exits.

You have to be careful, because without using `await` the program may **finish before the parallel thread completes** if the main thread ends quickly. When you start a parallel thread using `Task.Run(...)` **without `await`**, the main thread **does not wait** for it. If the main thread finishes its execution quickly (like reaching the end of `Main`), the entire program may **exit** before the parallel thread finishes its work — especially if that thread is doing something slow (e.g., `Thread.Sleep`). This is because the application exits as soon as all foreground work in `Main` is done, regardless of background threads still running.

This is clearly visible in the example below where the `Async()` method will never finish:

```csharp
class Program
{
    static async Task Main()
    {
      Async();

      Console.WriteLine("Main Method finishes.");  
    }

    static async Task Async()
    {
        Console.WriteLine("Entering Async Method.");

        await Task.Delay(3000);

        Console.WriteLine("Async Method finishes.");
    }
}
```

**There is a distinction:**

- In a **console app**,  if the `Main` method finishes before the `async` method completes (and you're not awaiting it), the process may exit early, and the async method might **never complete**.
    
- In **ASP.NET**, the method won’t be aborted immediately, but:
    
    - It becomes **detached** from the request lifecycle.
        
    - It may finish later — but you’ve lost the ability to observe or manage it (unless you explicitly track it).
        
    - **Unobserved exceptions** can go unnoticed.

	- ASP.NET **won’t capture errors**, and **won’t delay the HTTP response** based on that background operation.

	- It behaves like a background task — so it **might or might not finish**, depending on timing and whether the app shuts down before it's done.
#### `Task.Wait()`
To make sure the program **waits for the parallel task to finish**, even without using `await`, you can store the `Task` and call `.Wait()` on it.

Here’s how:

```csharp
class Program
{
    static void Main()
    {
        // Store the task reference
        Task task = Task.Run(() => ParallelThread());

        for (int i = 0; i <= 100; i++)
        {
            Console.WriteLine($"Main thread in for loop, i = {i}");
        }

        Console.WriteLine("Main thread waiting for the parallel thread to finish...");

        // Force the main thread to wait for the task to complete
        task.Wait();

        Console.WriteLine("Main thread finishes.");
    }

    static void ParallelThread()
    {
        for (int i = 0; i <= 100; i++)
        {
            Console.WriteLine($"Parallel thread in for loop, i = {i}.");
        }

        Thread.Sleep(3000); // Simulate longer work
        Console.WriteLine("Parallel thread finishes.");
    }
}
```

🔍 **Explanation:**

- `Task.Run()` launches the background task.

- `.Wait()` pauses the main thread until the parallel task completes.

- This ensures the application won’t exit early, even if the background work takes longer.

- If you have **multiple parallel methods**, you should store **each `Task`** separately and then wait for **all of them together** using `Task.WaitAll(...)`.
### `await` and `async` — How They Help
When you use the `async`/`await` pattern:

- **Awaiting** on an operation means **releasing** the thread to the thread pool, freeing up CPU time for other threads.

- The CPU doesn’t keep allocating resources to the thread while it is "awaiting" a task. This is a big benefit: instead of wasting CPU time, it **suspends** the thread and allows the CPU to do other useful work.

So, by using `await`, the thread **doesn't take up CPU time** when it's not performing any meaningful work. It essentially "pauses" its execution, allowing the CPU to handle other threads.

**Summary**

- **Without `await`**: If a thread is running an operation (even an idle one), it **still takes CPU resources** because it remains on the scheduling queue.

- **With `await`**: The thread is **released** and doesn't take up CPU time until the awaited operation completes, allowing the CPU to work on other threads.

Thus, if your thread is **doing nothing** (or blocked), it still consumes resources **unless you use asynchronous programming** (`async`/`await`), which allows the CPU to efficiently allocate resources elsewhere.
## Thread Management and Parallel Execution
A **thread** is essentially a unit of work that corresponds to a specific part of a program that is running. Each thread has its own **call stack** (e.g., 1MB in .NET by default). It’s like an individual **worker** assigned to handle a task. However, threads themselves are not physically tied to any specific CPU core. Instead, they are more **logical** in nature. The **operating system** and **scheduler** decide how and where they will run, optimizing performance based on available resources.

🧠 **Breakdown Example:**

🧩 **Hardware:**

You have 10 **physical cores**, but each of these cores can handle **2 logical cores** (hyper-threading).  
So, in total, you have **20 logical cores** (or **20 workstations**) that can run threads in parallel.

⚙️ **How the Scheduler Works:**

The **scheduler** is like a **manager** who assigns tasks (threads) to the available workstations (logical cores).

- The **scheduler** can assign threads to these 20 workstations (logical cores).

- It keeps track of how much work each core is doing (the load).

- If one workstation (logical core) is overloaded and does not have enough processing power (the **capacity** of a core to allocate time for each thread to run), the scheduler can **move** threads from one core to another to balance the workload and improve efficiency.

🔄 **Thread Movement:**

- The **scheduler** doesn’t just stick to one physical core.

- If a thread is running on logical core 1 (on physical core 1) and needs more resources (needs **more uninterrupted or timely CPU attention**, which translates to **more execution time**), the scheduler may **move it to logical core 19** (on physical core 10) to optimize performance.

- This movement is **transparent** to the program – it's managed entirely by the operating system and its scheduler.

🏗️ **Analogy: Workers and Desks**

|**Element**|**Analogy**|
|---|---|
|**Logical Core**|A **work desk**|
|**Physical Core**|A **room** with desks|
|**Thread**|A **worker**|
|**Scheduler**|The **manager**|
|**Program**|A **task** being done by workers|

🧑‍💼 **What’s Happening in the Office:**

1. You have **20 desks** (logical cores).

2. You have many **workers** (threads).

3. The **manager** (scheduler) assigns workers to desks.

4. The manager ensures no one is left idle, and if a desk is overloaded, workers can be moved between desks.

🔑 **Important Concepts to Remember:**

1. **Threads are Logical:**

    - Each **thread** corresponds to a specific part of the program you’re running, like a worker assigned to a task.

    - The thread is **not bound** to a specific CPU core. It’s a **logical concept** that represents a segment of the program.

2. **Schedulers Control Assignment:**

    - The **scheduler** decides which thread gets executed on which logical core.

    - If there are more threads than available logical cores, the scheduler switches threads in and out of the cores as needed to maximize efficiency.

3. **Physical Cores & Logical Cores:**

    - You can have more threads than physical cores because of **hyper-threading**. Each physical core can handle multiple threads (logical cores).

    - In our example, with **10 physical cores** and **20 logical cores**, the scheduler has **20 places** to distribute the threads, but the threads themselves are not directly tied to these cores.

📌 **Conclusion:**

- **Threads** are the tasks your program does, and they are not tied to specific CPU cores. They are **logical constructs**.

- The **scheduler** (the office manager) assigns these threads to the available logical cores (desks).

- **Threads can move** between logical cores as needed, depending on the system’s needs and the scheduler's decisions.

- So, even though you may have 10 physical cores, **20 logical cores** give you **20 workstations** where threads (tasks) can run **in parallel**. The **scheduler** makes sure no workstation is idle unless necessary.

This allows efficient handling of tasks and better **parallelism**, improving the performance of your program!

**🧵 Thread Lifecycle**

1. **Own Call Stack**

    - Every thread has its own **call stack** — this holds the function calls, local variables, and return addresses used by that thread only.

    - This separation is what allows multiple threads to run concurrently without stepping on each other’s toes.

2. **Termination**

    - When a thread finishes its execution (e.g., the code inside it ends or is aborted):

        - Its **stack is cleared**.

        - All **resources are released** (unless something is leaked).

        - The thread is **removed from the scheduler’s queue**.

        - It essentially **ceases to exist**.

3. **After Termination**

    - It’s no longer part of the process.

    - It doesn’t consume CPU time, memory, or appear in system monitoring tools.


Think of it like a temporary worker at a workstation: once their job is done, their desk is cleaned out and someone else may use that spot. 🪑✅

**You said:**

In theory, we can create a program with 5,000 threads, but depending on how heavy each thread is, the processor will take significantly more time to handle them. After all, it only has about 20 "work desks" (cores or logical processors) to process those 5,000 threads—along with all the threads coming from other programs and the operating system itself, is this correct?

**ChatGPT said:**

Exactly — that's **absolutely correct**.

🧠 Here's how it plays out:

You can absolutely create **5000 threads** in your program (the OS usually allows tens or hundreds of thousands, depending on available memory). But here's what happens:

**⚙️ Real-World Impact of 5000 Threads:**

🔢 1. **Limited CPU Work Desks**

If your CPU has 20 **logical cores** (work desks), the OS scheduler can _only_ run 20 threads at the **same exact time**.

The other ~4980 threads will be:

- Sitting in a **queue**

- Or being **paused** (preempted) while others take turns

📊 2. **Scheduling Overhead**

With more threads:

- The **scheduler works harder** to juggle which thread runs next

- This can lead to **context switching overhead**, where threads are frequently paused/resumed, which consumes CPU cycles

🕒 3. **Execution Time Increases**

If the threads are **CPU-intensive**, the program can become **slower**, not faster. You’re dividing limited time between too many heavy tasks.

💾 4. **Memory Usage**

Each thread has its own **call stack** (e.g., 1MB in .NET by default), so 5000 threads = **~5GB of memory** just for stacks — not including your actual app logic.

👥 5. **Competition with Other Apps**

You’re not alone. The OS and other apps also create threads. All of them share the same pool of CPU cores.

**📌 Summary:**

- Yes, you can create thousands of threads.

- But only a small number (equal to the number of logical cores) can run simultaneously.

- The rest will wait their turn.

- Having **too many threads can degrade performance** due to overhead and resource contention.

**You said:**

A thread is always associated with a single program—more specifically, with a particular part of that program, such as the main thread.

**ChatGPT said:**

✅ Exactly — a **thread is always associated with a single process (program)** and handles the execution of **a specific path of code** within that program.

🧠 **Breakdown:**

- **A process** = your running program

- **A thread** = one flow of instructions inside that program

- The **main thread** starts executing the `main()` method (or its equivalent)

- You can then create **additional threads** to run other parts of the program concurrently (e.g., handling UI, network, or background tasks)

🔒 **A thread cannot:**

- Jump between programs

- Execute code from another process

It lives, runs, and dies **inside the boundaries** of the program (process) that created it.

**You said:**

If a thread in an ASP.NET controller reaches an `await` in an async method and gets released, is that thread terminated? And when a new request hits the controller, is a new thread created to handle it?

**ChatGPT said:**

Great question — and you're thinking exactly in the right direction when it comes to **asynchronous execution** and **thread management**.

Let’s break it down with your example:

🧩 **Scenario:**

You have a **web controller** (say in ASP.NET Core) with an `async` method. Inside that method, you `await` something like `await SomeIOOperationAsync();`

🔁 **What happens when `await` is hit:**

1. **The current thread is _not deleted_** — but it is **released back to the thread pool**.

    - It _stops executing_ your method and becomes available for other work.

2. The method’s **state is saved** (by the compiler-generated state machine).

    - This includes local variables and the exact line to resume from.

3. When the awaited operation (e.g., a DB call or HTTP request) **completes**, the continuation of your method is:

    - **Queued** to resume — typically on a **different** thread from the pool.

    - There is **no guarantee it will be the same thread** as before.

🧵 **So what about new requests?**

- Yes, when a **new request hits** your controller:

    - A **new thread from the thread pool** is assigned to handle that request.

    - It executes the controller action up until it hits any `await`.

    - Then it's returned to the pool and reused for other tasks.

📌 **Summary:**

- **Threads are not deleted** after an `await`; they’re just returned to the pool.

- **Continuation** after the await may run on a **different thread**.

- **Each new HTTP request** is handled by a separate thread from the pool.

**You said:**

But if a new thread handles the resumed async operation, does it also receive the original call stack?

**ChatGPT said:**

Great question! Let's clarify that:

When a thread is released after hitting an `await` in an `async` method, **the call stack** does not directly carry over to the new thread that resumes the operation. Here's a more detailed explanation:

**The Flow of Execution (Breaking It Down)**

1. **Before `await`:**

    - When your thread is running the method, it has a **call stack** (local variables, execution state).

    - You’re executing some code (let’s say doing some calculations or processing).

2. **Hitting `await`:**

    - When you reach `await`, the **current thread is released back to the pool**. However, the method’s execution doesn’t completely stop.

    - The **state of the method** (local variables, current line of execution, etc.) is saved in a **state machine** generated by the compiler.

    - This **state machine** is responsible for resuming execution after the awaited operation completes.

3. **Resumption on a New Thread:**

    - When the awaited operation completes (e.g., data is fetched or IO is done), the **task scheduler** picks a thread from the pool to resume execution.

    - However, **this new thread does not carry the original call stack**. Instead:

        - It picks up the **state machine** that was saved when `await` was hit, which contains the method’s execution state (the call stack is not literally transferred).

        - The new thread **executes the next part of the method** where it left off, using the **saved execution context**.

    - This is why asynchronous methods don’t require the exact same thread to resume — only the **execution state** is needed.

🧠 **Why the Call Stack is Not Passed:**

- **Call Stack**: It's specific to each thread, containing information about function calls, local variables, etc. Once a thread is released, its call stack is discarded.

- **Execution State**: This refers to the data that is needed to resume the method (like local variables, the point in the method where execution paused, etc.). This state is saved in a **state machine** and can be picked up by any thread.

📌 **In Conclusion:**

- A **new thread** picks up where the `await` left off using the saved **state machine** and does not need the original call stack.

- The **new thread** doesn't carry over the exact "call stack" but continues the execution by referencing the saved **state**.

**You said:**

If we don't release a thread using the async/await pattern, will the CPU cores still spend processing time on it—even if it's doing nothing—just to keep it alive?

**ChatGPT said:**

Yes, you're absolutely right. If a thread doesn't reach an `await` and continues to run while doing nothing meaningful, it will still consume CPU resources, even if it isn't performing any useful work. Let's break this down:

**How Threads Work When They Are "Idle" or "Doing Nothing"**

- When a thread is executing in your program and **isn't performing any useful work**, such as being blocked on I/O, waiting, or just idling, it still occupies a **slot** on a CPU core.

- It remains active, meaning it's still **waiting for its turn** in the CPU scheduling queue, even if it's not executing any important task.

This can happen if the thread:

1. **Is blocked** — such as waiting for a resource, like a file, or another operation, or if it is **waiting synchronously** (e.g., `Thread.Sleep()` or `Thread.Wait()`).

2. **Is running an infinite loop** — without yielding control back or waiting on any condition.

3. **Does nothing** — i.e., it’s simply running and consuming resources, like memory, but not performing any meaningful operation.

CPU Consumption and Scheduler

- **CPU Time**: If a thread is active, even if doing nothing, it will **consume CPU time**. The CPU scheduler will assign some processing time to the thread to allow it to run, even if it doesn't do anything productive.

- **Idle Thread (Not Yielding)**: If you have a thread that doesn’t yield control (such as an infinite loop without waiting for any event), it will **continuously use CPU resources**. This is inefficient because it **prevents other tasks from executing**.

**You said:**

What about the thread pool—does the program dynamically decide when to create and remove threads? And is there a limit to the number of threads an ASP.NET application can create?

**ChatGPT said:**

Yes, thread pooling and thread management are key aspects of how applications, like those in ASP.NET, handle concurrency efficiently. Let's dive into thread pools, how the program dynamically handles threads, and whether there are limits to the number of threads an ASP.NET application can create.

1. **What is a Thread Pool?**

- A **thread pool** is a collection of reusable threads managed by the operating system or the application. Instead of creating and destroying threads for each request, which is expensive in terms of system resources and time, the system **reuses existing threads** from the pool.

- Thread pools allow for **efficient handling of concurrent tasks** by reducing the overhead of repeatedly creating and destroying threads. The threads are allocated, used, and then returned to the pool after completing their task, ready to be reused.

2. **Thread Pool in ASP.NET**

- In ASP.NET, **task-based programming** (with `async/await`) and thread pooling play important roles in how threads are managed for web requests.

- **ASP.NET** (and other .NET applications) rely on the **.NET thread pool**, which is managed by the .NET runtime.

- When a request is made, **ASP.NET schedules the task** (such as handling a request in a controller) on a thread from the pool. Once the task is completed, the thread is returned to the pool.

- **Asynchronous programming** (using `async/await`) allows ASP.NET to be **non-blocking**, meaning it can release threads back to the pool during I/O-bound operations (e.g., waiting for a database query, file I/O) instead of keeping a thread occupied during that time.

3. **Dynamic Thread Creation and Deletion**

- **Dynamic Thread Creation**: The thread pool is managed by the operating system and the runtime, which means it dynamically creates threads when needed. However, the pool starts with a certain minimum size (a small number of threads) and can **expand** as needed when the demand for threads increases.

- **Thread Deletion**: Threads in the pool are not deleted when they complete their task. Instead, they are returned to the pool for reuse. However, after a period of inactivity, threads in the pool may be **recycled** or destroyed to save system resources, depending on the configuration of the thread pool and the runtime environment.

4. **Limit on Thread Creation**

- **Thread Pool Limits**: Yes, there are limits to how many threads the thread pool can create in an ASP.NET application, but these limits are dynamic and depend on several factors:

    - **Maximum Threads**: The thread pool has a **maximum number of threads** that it can allocate, which is typically determined by the operating system and configuration settings. For example, on Windows, the thread pool can create a large number of threads, but the number is finite to avoid overwhelming the system.

    - In ASP.NET, the maximum number of threads in the pool is usually set to a reasonable value based on the system’s resources and workload requirements.

- **Thread Pool Settings in .NET**:

    - The default **maximum number of threads** that can be created is usually determined automatically by the system based on the number of processors available.

    - You can **configure the thread pool** using the `.NET ThreadPool` class (e.g., `ThreadPool.SetMinThreads()` and `ThreadPool.SetMaxThreads()` methods) if you need more control over the minimum or maximum number of threads.

    However, these settings are typically adjusted based on system load and the available resources.

- **Blocking and Starvation**: If all threads are in use and new threads are needed, the requests might be queued up (waiting for a thread to become available). If the system is overwhelmed and doesn't have enough threads to handle all incoming requests, the system may experience **thread starvation**, where threads are not able to process tasks in a timely manner.

  This is why it's important to ensure that the thread pool isn't overwhelmed. In high-load applications, strategies like **asynchronous programming** or **offloading work to background queues** can help prevent blocking the main thread pool.

5. **Scaling and Resource Management**

- **Thread Pool Scaling**: The thread pool in ASP.NET can dynamically scale to meet demand, but it will be constrained by system resources (like CPU and memory) and the configured settings. The pool can **grow** to accommodate more threads when necessary, but it will also **shrink** when demand decreases, returning unused threads to the system.

- **System Resources**: While you can adjust thread pool settings, there are physical system limitations, such as CPU core count and memory, which will influence how effectively the thread pool can scale.

6. **Handling High Concurrency in ASP.NET**

- ASP.NET makes heavy use of **asynchronous I/O** operations to avoid blocking threads. For example, when an HTTP request is handled, the server may initiate an async I/O operation (like database queries or HTTP calls) and **release the thread back to the pool** while waiting for the operation to complete.

- This allows ASP.NET to handle **thousands of concurrent requests** efficiently, without consuming excessive resources for each one.

- The **Thread Pool** is particularly useful for handling **CPU-bound tasks** or tasks that involve long-running operations, as the threads can be reused for other tasks when not in use.

7. **Why Thread Pools are Efficient in ASP.NET**

- **Reducing Overhead**: Without a thread pool, the system would need to create and destroy threads for every request, which is an expensive operation. The thread pool eliminates this overhead by keeping threads ready for reuse.

- **Avoiding Thread Creation Bottlenecks**: If your application is handling high concurrency, thread creation and destruction can become a bottleneck. The thread pool mitigates this by keeping threads ready to handle multiple tasks without needing to create new threads for each one.

- **Efficient Resource Management**: Thread pools allow the system to balance between having enough threads to handle requests and avoiding having too many threads, which could saturate the system’s CPU and memory.

Summary:

- **Thread Pool**: ASP.NET uses a thread pool to manage threads efficiently. Threads are **reused** rather than created and destroyed for each request.

- **Dynamic Creation**: The thread pool dynamically creates threads when needed, within limits, and manages their lifecycle (releasing or recycling threads).

- **Limits**: There are limits to how many threads the pool can create, typically configurable by the system and developer. These limits depend on available system resources and configuration settings.

- **Efficiency**: Thread pools are key to handling high concurrency without overwhelming the system. Asynchronous programming in ASP.NET ensures threads are not kept busy unnecessarily, freeing up resources for other tasks.

This setup enables ASP.NET to handle a large number of concurrent requests efficiently, but it's essential to monitor and adjust thread pool settings, particularly for applications with high throughput or demanding workloads.

**You said:**

*"When a request is made, ASP.NET schedules the task (such as handling a request in a controller) on a thread from the pool. Once the task is completed, the thread is returned to the pool. Asynchronous programming (using async/await) allows ASP.NET to be non-blocking, meaning it can release threads back to the pool during I/O-bound operations (e.g., waiting for a database query, file I/O) instead of keeping a thread occupied during that time."*

So even if we don’t use `async/await`, many users can still interact with the application without it freezing. However, this means a new thread must be used for each user request, which can eventually exhaust the thread pool if the number of concurrent users grows large?

**ChatGPT said:**

Yes, you're correct! Even without using `async/await`, ASP.NET can handle multiple concurrent requests, but there are some important considerations about how threads and the thread pool are managed.

**Here's how it works:**

1. **Handling Requests Without `async/await`**:

    - When a user sends a request to an ASP.NET application, a thread from the thread pool is assigned to handle that request. If the request involves CPU-bound operations (e.g., processing data), the thread will be kept busy until the task completes. This means the thread is **blocked** during that time and cannot be reused for another request until it finishes its task.

    - **If multiple users are making requests simultaneously**, ASP.NET will assign additional threads from the thread pool to handle those requests, assuming there are threads available. This works fine as long as the thread pool has enough resources to allocate threads for each incoming request.

2. **Impact on the Thread Pool**:

    - **More Users = More Threads**: If you have many concurrent users, and each request requires a thread from the pool, the number of threads being used will increase. The thread pool has a **limited number of threads** that can be allocated at any given time (although the size of the pool can grow dynamically depending on system resources and configuration).

    - As you get more users and more threads are allocated, the thread pool can get **exhausted** if there are too many simultaneous requests. This can cause **thread starvation**, meaning requests will have to wait for a thread to become available. If the pool is saturated and there are not enough threads to handle requests, the application may experience delays or timeouts.

3. **Asynchronous Programming (`async/await`)**:

    - When you use `async/await`, the key advantage is that you **release the thread back to the pool during I/O-bound operations** (like waiting for a database query or making HTTP requests). This makes it non-blocking, meaning the thread is not sitting idle while waiting for these operations to complete. Instead, it is free to handle other requests.

    - This way, you can **handle many more concurrent requests** without consuming additional threads for tasks that would otherwise be blocked (such as waiting for database queries or file I/O). The **async thread does not occupy a thread** while waiting, which greatly reduces the load on the thread pool.

**To clarify:**

- **Without `async/await`**: Each request occupies a thread in the pool for the entire duration of the request's processing, even if the request is waiting for I/O (like database queries). This can quickly fill up the thread pool when there are many concurrent requests.

- **With `async/await`**: The thread is released back to the pool while waiting for I/O, which means the thread is not blocked, and the same thread can be reused to handle other requests. This improves the scalability of the application, allowing it to handle many more concurrent requests without running into thread pool limits.

**Example:**

- Suppose you have a web application with 1000 concurrent requests and no `async/await`:

    - Each request uses one thread in the pool for its entire duration, even if it's waiting for a database query. If each request takes a long time (e.g., 5 seconds), the thread pool will be consumed very quickly, and requests will start waiting for available threads, potentially leading to a slow application or timeouts.

- With `async/await`:

    - When a request reaches an `await` (e.g., waiting for a database query), the thread that was handling the request is released back to the pool, and a new thread is not needed for the waiting period. After the I/O operation completes, the thread pool picks up the continuation of the request and resumes processing. This means the system can handle **many more concurrent requests** without running into the same thread pool exhaustion problem.

**Thread Pool Management:**

ASP.NET and the .NET runtime are quite efficient at managing the thread pool, but it still has limits:

- **Minimum Threads**: There is a minimum number of threads that are always available in the pool, even under low load.

- **Maximum Threads**: There is also a maximum number of threads the pool can grow to, depending on the system's resources and the configuration.

If your application uses `async/await` properly for I/O-bound operations, the **thread pool usage is much more efficient**, and you can scale better with higher concurrency. On the other hand, if you're handling a lot of CPU-bound tasks or blocking I/O, the thread pool will quickly become a bottleneck as threads get occupied for longer periods of time.

**Conclusion:**

- Even without `async/await`, your ASP.NET application can handle concurrent requests, but the threads in the thread pool are occupied for the full duration of the request, which limits the scalability.

- With `async/await`, you improve scalability by releasing threads during I/O-bound operations, allowing more users to interact with your application without overloading the thread pool.

So yes, without `async/await`, every user request will use a new thread from the thread pool, and as the number of users increases, the thread pool will eventually become full, potentially slowing down the system.
## `Thread(...)` vs `Task.Run(...)`
`new Thread(...)`

- **Always creates a new OS thread**.

- Higher memory and scheduling overhead.

- Gives full control over the thread (e.g., priority, lifetime).

- Useful for long-running or isolated operations.

`Task.Run(...)`

- **Queues the work to the `ThreadPool`**.

- Reuses existing threads if possible (more efficient).

- Thread lifetime is managed by the `ThreadPool`.

- Preferred for short-lived, I/O-bound, or background tasks.

**Example:**

```csharp
// Creates a new, dedicated thread
Thread thread = new Thread(() => Console.WriteLine("Hello from Thread!"));
thread.Start();

// Uses ThreadPool
Task.Run(() => Console.WriteLine("Hello from Task!"));
```

With `System.Threading.Thread` you're demanding a new thread directly, while `Task.Run` is a **request for asynchronous execution**, and the runtime decides the most efficient way to do it.
## `ThreadPool` vs Dedicated Thread - Efficiency vs Control
**✅ The `ThreadPool`:**

- **Reuses real OS threads**, but we don't control them directly.

- Think of them as **"logical workers"** managed by the .NET runtime.

- `ThreadPool` threads are **backed by real threads**, but not one-to-one.

- They're designed for **short-lived, background, non-blocking tasks**.

- Efficient because they **avoid the overhead** of creating and destroying threads.

- The number of threads is **dynamically adjusted** by the runtime based on workload and system resources.

✅ **`new Thread(...)` (`System.Threading.Thread`):**

- Always creates a **dedicated, real OS thread**.

- That thread is mapped to a **hardware thread** (or scheduled by the OS across cores).

- These are more **resource-intensive**.

- Gives more control but less efficient if overused.

- Useful when you need:

    - Long-running tasks

    - Thread affinity

    - Explicit control over thread lifetime

✅ **Physical cores and threads:**

- A **CPU core** can run one or two hardware threads simultaneously (with **Hyper-Threading**).

- But the OS may schedule **hundreds of logical threads** on a limited number of cores.

- These logical threads **take turns** using the available physical cores, managed by the OS scheduler.

**Dedicated Threads vs `ThreadPool` – Resource Control vs Optimization**

When you use `new Thread(...)`:

- You're **reserving a dedicated OS thread**.
    
- That thread is **not managed by the `ThreadPool`**.
    
- It stays alive until it finishes, even if it's idle — so it **consumes more resources**.
    
- You're **taking away a thread** that could otherwise be reused by the framework for other tasks.
    
- This **reduces overall efficiency**, especially if you create many such threads.
    
- The **`ThreadPool` is optimized** to manage limited resources by:

    - Queuing work

    - Scaling the number of threads dynamically

    - Reusing threads to avoid expensive creation/destruction

**✅ In short:**

Using `ThreadPool` (e.g., via `Task.Run`) allows the .NET framework to **optimize CPU usage and resource allocation**.  
Manually creating threads with `new Thread()` should be **reserved for very specific needs**, like:

- Long-running background work

- Threads with special affinity or isolation

- Real-time systems where you need strict control

🧠 **Summary:**

You can think of **`ThreadPool` threads as lightweight, reused wrappers around real OS threads**, while `new Thread()` creates a fresh **dedicated OS thread**, consuming more resources and bypassing the optimization of the pool.
Using `new Thread()` gives you full control but consumes more system resources and bypasses the .NET `ThreadPool`. In contrast, `Task.Run` leverages the `ThreadPool` for efficient, scalable, and optimized thread management. Use dedicated threads only when you need strict control or isolation.
### Thread vs. Task: Main Difference
```csharp
// Using Task.Run()
class Program
{
    static void Main()
    {
        // Start a new task using the thread pool to run ParallelThread asynchronously
        Task.Run(() => ParallelThread());

        Console.WriteLine("Main thread finishes.");
    }

    static void ParallelThread()
    {
        for (int i = 0; i <= 100; i++)
        {
            Console.WriteLine($"Parallel thread in for loop, i = {i}.");
        }

        Console.WriteLine("Parallel thread finishes.");
    }
}

// Using Thread
class Program
{
    static void Main()
    {
        // Creating and starting a new thread
        Thread t = new Thread(() => ParallelThread());
        t.Start();

        Console.WriteLine("Main thread finishes.");
    }

    static void ParallelThread()
    {
        for (int i = 0; i <= 100; i++)
        {
            Console.WriteLine($"Parallel thread in for loop, i = {i}.");
        }

        Console.WriteLine("Parallel thread finishes.");
    }
}
```

1. **`Task.Run()`**:

    - A `Task` is not necessarily tied to a **physical thread** in the same way. When you use `Task.Run()`, the task is typically scheduled to run on a **`ThreadPool` thread**, which is a managed set of threads in .NET.

    - If the main thread exits before the task completes, the **`ThreadPool`** may decide to terminate the task or allow it to run, but the main thread **won't wait** unless you explicitly tell it to wait (e.g., `task.Wait()`).

    - `Task` is part of a **higher-level abstraction** provided by the .NET runtime that manages threads for you. The **`ThreadPool`** reuses threads, and if the main thread exits, the task may not continue running (depending on the environment and the way the thread pool is managed).

2. **`Thread`**:
    - When you use `new Thread(...)`, you're creating a new **physical thread** that runs independently of the main thread. The new thread will continue executing its code until it finishes, regardless of whether the main thread is still running or has already finished.
    
    - The **thread is independent**: The application doesn't automatically wait for a `Thread` to finish unless you explicitly tell it to (e.g., using `Join()`).

    - This is why the `Thread` continues running after the main thread finishes, as it's a separate **system thread** managed by the OS, and it doesn't "die" when the main thread exits.

Why Does a `Thread` Continue After the Main Thread Exits?

- **Threading model**: When you create a `Thread`, you're directly managing a physical OS-level thread. The OS doesn't care if your main thread finishes; the background thread continues running until it finishes its execution.

- **Thread lifecycle**: The lifecycle of a `Thread` is independent of the main thread. The main thread can finish, but the background thread will still execute until it completes its task (unless the OS terminates the process).

Why Does `Task.Run()` Behave Differently?

- **Task scheduling**: A `Task` runs on a thread managed by the **`ThreadPool`**, and the `ThreadPool`'s threads can be reused by other tasks or threads, especially if the main thread finishes quickly. The lifecycle of a `Task` is also more dependent on the thread pool and may be affected by things like **garbage collection** or **thread pool management**.

- **Main thread exit**: If the main thread finishes and the only remaining task is a background `Task`, the runtime may decide that the process can be terminated, as there are no more active threads running from the perspective of the application (especially in cases where no `task.Wait()` or `task.Result` is used). This can cause the program to exit before the task finishes.

**Why the `Thread` Doesn't Stop When Main Thread Exits:**

- A `Thread` is a **system thread**, and the OS manages its execution independently of the main thread. When you call `Start()` on a `Thread`, it schedules the thread for execution, and it will keep running until it's finished — the main thread exiting doesn't stop the thread unless explicitly terminated.

**Conclusion:**

- **`Thread`**: The background thread will continue running even after the main thread exits because it's an independent system-level thread.

- **`Task.Run()`**: The task is scheduled in the **`ThreadPool`**, and the runtime may decide to terminate the application once the main thread finishes if no other tasks are actively running.

This distinction is important in scenarios where you want a background operation to continue running after the main thread finishes. If you want to ensure the task or thread completes before the program exits, you can use `task.Wait()` for tasks or `thread.Join()` for threads.
If you want the behavior of the `Thread` to match the `Task` (in terms of stopping when the main thread finishes), you could explicitly handle the completion of the `Thread` using `Thread.Join()` or other synchronization mechanisms. 
## `await / async` Pattern
✅ **When a method is marked `async`:**

1. **It's just like a normal method** — until it hits an `await`.

    - All synchronous code runs **immediately**, just like in a normal method.

    - The `await` is where the method **can pause** and yield control, allowing other work to happen.

2. **It must return** one of the following:

    - `Task` — if it returns nothing

    - `Task<T>` — if it returns a result

    - `void` — only in specific cases (e.g., event handlers; not awaitable)

In an `async` method, the compiler **automatically wraps** your return value in a `Task` or `Task<T>` behind the scenes.

- If the method is `async Task`, you don’t need to return anything explicitly — the compiler returns a `Task` for you.

- If the method is `async Task<T>`, you just `return` a value of type `T`, and the compiler wraps it in a `Task<T>`.

- All non-`void` `async` methods **always return a `Task` or `Task<T>`** — never the raw value directly.

✅ **Differences between a normal method and an `async` method:**

|Feature|Normal Method|Async Method|
|---|---|---|
|Can use `await` inside|❌ No|✅ Yes|
|Return type|Any (`void`, value)|Must be `Task`, `Task<T>`, or `void`|
|Execution|Immediate, all code|Immediate until `await`|
|Asynchronous behavior|❌ No|✅ Yes, if using `await`|

🧠 **Key Insight**

If you **mark a method `async` but never `await` anything inside**, it's still valid, but:

- It will **run synchronously**.

- The compiler will give a **warning**: "This async method lacks 'await' operators and will run synchronously."

🧪 **Example**

```csharp
async Task SayHello()
{
    Console.WriteLine("Hello");  // runs immediately
    await Task.Delay(1000);      // yields control here
    Console.WriteLine("World");  // resumes after delay
}
```
### await
In asynchronous programming, **`await`** is a powerful tool that helps manage the flow of your program without blocking threads. Here's how it works and why it's important:

**What `await` Does:**

1. **"Don't Continue Until This Task Finishes"**:

    - The keyword `await` tells the program to **pause execution** at that point until the asynchronous operation (represented by a `Task`) completes.

    - The program **does not continue** past the `await` statement until the task is finished. However, this pause is **non-blocking**, meaning the thread is free to handle other tasks while waiting for the asynchronous operation to complete.

    **Example**:

```csharp
public async Task<int> FetchDataAsync()
{
    var data = await GetDataFromDatabaseAsync();
    return data;
}
```

In this example, the `FetchDataAsync` method will wait until `GetDataFromDatabaseAsync()` completes. The program won’t continue executing after the `await` statement until it has the result from the database.

2. **Automatic Unpacking of the Result**:

- When you use `await` on a `Task<T>`, it automatically "unwraps" the result from the `Task`. This means you can access the returned value directly without needing to call `.Result` or `.Wait()`, which are often used in synchronous code.

**Example:**

```csharp
var result = await FetchDataAsync();
Console.WriteLine(result);  // Accesses the result directly
```

**How `await` Differs from `.Result`**:

- When you use `.Result`, you are **explicitly blocking the thread** until the `Task` completes. This means the thread is **not idle**; instead, it is actively waiting, preventing it from doing any other work during that time. In other words, the thread is **blocked**, not free to be used elsewhere, which **defeats the purpose of asynchronous programming**—where the goal is to allow threads to be free to do other work while waiting for a task to complete.

**Example (Blocking):**

```csharp
var result = myTask.Result;  // Blocks the thread until myTask finishes
Console.WriteLine(result);
```

Using `.Result` blocks the current thread until `myTask` completes, which can lead to performance issues, especially in UI or server-side applications where responsiveness is important.

**Why `await` is Preferred**:

- **Non-blocking**: `await` allows the program to continue executing other tasks in the background while waiting for the task to complete. The thread is not blocked, meaning it can handle other operations during the wait.

- **Automatic Unpacking**: Using `await` simplifies the code since you don’t have to deal with manually extracting the result from the `Task` object. It makes asynchronous code cleaner and more readable.

**Conclusion**:

- **`await`** is used to pause execution without blocking the thread, allowing for efficient, asynchronous operations.

- **It automatically unpacks** the value from the `Task`, so you don’t need to use `.Result` (which blocks the thread).

- **Avoid blocking the thread** with `.Result` or `.Wait()` in asynchronous code, as these can lead to performance bottlenecks and defeat the purpose of asynchronous programming.

By using `await`, you ensure that your program remains responsive, especially in scenarios involving I/O-bound tasks like file reading, network requests, or database queries.
## CSharp Task vs JavaScript Promise
**🧠 First, a key distinction:**

⚙️ **JavaScript:**

In JavaScript, the `Promise` class is the **core abstraction** of asynchronous computation. It is **manually constructed** and explicitly wired with an executor function:

```javascript
const promise = new Promise((resolve, reject) => {
    setTimeout(() => resolve(42), 1000);
});
```

⚙️ **C#:**

In C#, the core class is **`Task` / `Task<T>`**, and **not** a `Promise` class.

- The C# `Task` represents **an ongoing operation**, and yes, `async/await` is also **syntax sugar**, but it's built over `Task` and the **compiler-generated state machine**.

- Unlike JS, you do **not** manually wire `resolve` and `reject`. Instead, you rely on the `TaskCompletionSource<T>` class when you want to manually control task completion.


Example:

```csharp
var tcs = new TaskCompletionSource<int>();

// Somewhere in your code
tcs.SetResult(42);  // Like resolve
tcs.SetException(new Exception()); // Like reject

Task<int> task = tcs.Task;
```

✅ **Summary Comparison: `Promise` vs. `Task`**

|Feature|JavaScript `Promise`|C# `Task`|
|---|---|---|
|Base class|`Promise`|`Task` / `Task<T>`|
|Manual control|Yes (with `resolve`, `reject`)|Yes (with `TaskCompletionSource<T>`)|
|Syntax sugar|`async/await`|`async/await`|
|Threading|Single-threaded event loop|Multi-threaded, uses thread pool|
|Execution model|Event loop (non-blocking)|Thread pool or async IO (e.g., I/O Completion Ports)|
|Cancelation|No built-in cancellation|Yes (`CancellationToken`)|
|Exception handling|`.catch()` or `try/catch`|`try/catch` and `task.Exception`|
|Result access|`.then()` or `await`|`.Result`, `.ContinueWith()` or `await`|

💡 **Is `Task` like a `Promise`?**

**Yes, conceptually**: both are placeholders for future results.

**But implementation-wise**, C#’s `Task` is:

- Tied to the CLR thread pool and task scheduler.

- Often backed by OS-level asynchronous primitives (like overlapped I/O or completion ports).

- Able to be completed manually via `TaskCompletionSource`.


JavaScript Promises are:

- Lightweight and completely managed in the JS engine.

- Not tied to threads — they rely on the **event loop** and **microtask queue**.

- Always execute their `.then()` handlers asynchronously (after the current call stack clears).

🔧 **Behind the scenes in C#: `async/await`**

When you write this:

```csharp
async Task<int> Foo()
{
    await Task.Delay(1000);
    return 42;
}
```

The C# compiler:

- Transforms it into a **state machine**.

- It wires continuations via `TaskAwaiter` (e.g., `.GetAwaiter().OnCompleted()`).

- It schedules the rest of the method as a **continuation** once the `awaited` task completes.


So yes — similar to Promises and `.then()` in JS — **but entirely separate implementations.**

🔚 **In Short:**

- C# does **not** use Promises under the hood — it has its own powerful system with `Task`, `TaskCompletionSource`, and compiler-generated state machines.

- `async/await` is syntax sugar in both languages.

- They serve similar purposes but are implemented very differently due to the runtime environments (CLR vs JS engine).
# Bookmarks
Completion: 01.05.2025