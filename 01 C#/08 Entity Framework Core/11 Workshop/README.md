# General
## Entity Framework Core 8
### Complex Types

Комплексните типове в Entity Framework Core са концепция, която позволява групиране на свързани пропъртита в отделна структура, без тя да бъде самостоятелна таблица в базата данни. Това е полезно за моделиране на повторяеми данни, които нямат собствен първичен ключ.

**Характеристики на комплексните типове**

- Могат да съдържат **само примитивни типове** (напр. `string`, `int`) или **ентитетни типове**.
    
- **Нямат първичен ключ** и не могат да съществуват самостоятелно.
    
- Трябва да бъдат част от друг ентитет (не могат да се дефинират като `DbSet`).
    
- Могат да бъдат както **референтни типове**, така и **стойностни типове** в .NET.
    
- **Няколко пропъртита** могат да споделят една и съща инстанция на комплексен тип (за разлика от `Owned types`).
    
- Трябва да бъдат маркирани с атрибута `[ComplexType]`.

**Пример за комплексен тип**

```csharp
using System.ComponentModel.DataAnnotations.Schema;

[ComplexType]
public class Address
{
    public string Street { get; set; }
    public string City { get; set; }
    public string PostalCode { get; set; }
}

public class Customer
{
    public int Id { get; set; }
    public string Name { get; set; }

    public Address BillingAddress { get; set; }
    public Address ShippingAddress { get; set; }
}
```

**Обяснение на примера**

- Класът `Address` е дефиниран като комплексен тип чрез `[ComplexType]`.
    
- `Customer` съдържа два пропъртита от тип `Address`, което позволява споделяне на една и съща структура за различни цели (напр. адрес за доставка и адрес за фактуриране).

**Важно уточнение**

- В Entity Framework Core терминът **Complex Types** е заменен с **Owned Types**.
    
- При **Owned Types** всеки обект има своя отделна инстанция и не може да бъде споделен между различни пропъртита.

Ако имаме нужда от допълнителна информация или примери за `Owned Types`, можем да разгледаме и тази концепция.
### Collections of Primitive Types
PostgreSQL е сред малкото релационни бази данни с вградена поддръжка за колекции от примитивни типове.

EF Core 8 добавя поддръжка (не е била налична преди).

За бази данни, които нямат вградена поддръжка, ползваме JSON сериализация.

Данните се съхраняват в поддържани типове колони (например низове).

Минимално поддържаната версия на SQL Server е SQL Server 2016 (ниво на съвместимост 130).

За PostgreSQL най-добре е да се ползва с `IList<T>`.
### JSON Columns
Съхраняването на сериализирани данни става все по-често срещано.

Ползва се в документни бази данни (например MongoDB, Cosmos DB) или релационни бази данни.

PostgreSQL ползва `jsonb` (JSON blob) и предлага разширени SQL оператори и функции.

SQL Server ползва `varchar` и включва JSON функции.

EF Core 8 ползва `Owned Type`.

Методът за разширение `ToJson()` се ползва в `OnModelCreating`.
### Raw SQL Queries for Arbitrary Objects
EF 7 позволяваше скаларни резултати, но **EF 8** разширява възможностите с:

```csharp
SQL Query()
SqlQueryRaw()
```

Типовете резултати могат да използват атрибута **[Column]** за картографиране на колони към свойства.

Тези методи връщат **IQueryable**, което позволява използването на LINQ.

EF 8 оптимизира заявките, ако тя обработва цялото SQL, като така подобрява производителността.

Трябва да се внимава за SQL Injection.
### Default Values
**`HasDefaultValue()`** и **`HasDefaultValueSql()`** са методи за задаване на стойности по подразбиране в EF Core. Те се използват за задаване на стойности по подразбиране за дадени свойства на моделите.

**Sentinel Values**

- **Пред EF Core 8**: Използването на стойности по подразбиране е било базирано на стойностите по подразбиране на .NET (например `false` за булеви стойности и `0` за числа).
    
- **С EF Core 8**: Въвеждат се **sentinel стойности**, които позволяват да се зададат специални стойности за инициализация, които да се разглеждат като валидни "неизвестни" стойности в контекста на моделите.

**`HasSentinel()`**

EF Core 8 добавя метода `HasSentinel()`, който позволява задаването на стойности, които се разглеждат като sentinel стойности, а не просто стойности по подразбиране. Това е полезно за случаи, когато трябва да се отличават реалните стойности от тези, които се използват за означаване на "неинициализирани" или "липсващи" стойности.

**Стандартни стойности:**

- **Булев тип**: EF Core 8 разглежда стойността по подразбиране за булеви типове като `true` като sentinel стойност. Това означава, че ако няма зададена стойност за булевото свойство, `true` може да се третира като "незададена" стойност.
    
- **Енум тип**: При енумите, преди EF Core 8, е имало проблеми със стойностите по подразбиране, когато се използваха `0` или други стойности, които можеха да създадат неясноти. С EF Core 8 тези проблеми са по-добре обработени, като се въвеждат подходи за разпознаване на стойности по подразбиране в енумите.
### `ExecuteUpdate` & `ExecuteDelete`
Представени в EF Core 7, масовите операции като актуализации и изтривания биват въведени, а в EF Core 8 те биват подобрени.  
Тези операции позволяват директни масови актуализации и изтривания в базата данни без да преминават през стандартния workflow на EF, който включва Fetch (зареждане на данни), Track (проследяване на промените) и Save (запазване на промените).

Тези операции не трябва да се смесват с обичайния процес на актуализация през **Change Tracker**.  
Операциите **`ExecuteUpdate`** и **`ExecuteDelete`** не се проследяват от **Change Tracker-а**, което означава, че EF няма да записва промени в обектите или да проверява кои обекти са променени.  
Те се изпълняват незабавно в базата данни и не са част от **`UnitOfWork`** шаблона, което означава, че не се изпълняват като част от транзакцията за съхранение на промените.

Пример за масова актуализация в EF Core:

```csharp
context.Orders
       .Where(o => o.Status == "Shipped")
       .ExecuteUpdate(u => u.SetProperty(o => o.Status, "Delivered"));
```

Това актуализира всички поръчки със статус "Shipped" на "Delivered", без да се използва **Change Tracker**.

По дизайн тези операции трябва да засягат само една таблица.

EF Core 8 поправя проблем, който съществува в EF Core 7, като добавя поддръжка за **Owned Entities**.

В EF Core 7 възниква изключение, когато операцията се опитваше да достъпи две ентитита.

На практика обаче тези ентитита се съхраняват в една и съща таблица.
### Model Creating
#### Entity Types
При създаването на модела се препоръчва ползването на **Data Annotation**.

Ако обаче се налага ползването на **Fluent API**, е препоръчително конфигурацията да се извършва в отделни конфигурационни файлове.

Примери за ползване на Fluent API включват:

Изключване на таблица от миграциите.

Включване на изглед (View) в модела.

Ползване на атрибута **[Comment]** за добавяне на коментари на ниво таблица в базата данни.
#### Entity Properties
Винаги трябва да ползваме атрибута **[Comment]** за всяко пропърти.

Винаги трябва да задаваме максимална дължина за string пропъртита (освен ако изрично не се изисква текст или **varchar(max)**).

За задаване на максимална дължина ползваме **[MaxLength]** или **[StringLength]**.

Винаги ползваме **[Required]** за пропъртита, които не трябва да бъдат NULLable (за да избегнем объркване с nullable reference types).

За decimal пропъртита се препоръчва ползването на атрибута **[Precision]**.

Атрибутът **[Column(Order = n)]** може да се ползва за задаване на реда на колоните при създаване на таблицата.
#### Keys
За първичен ключ ползваме атрибута **[Key]** на ниво пропърти.

За съставен първичен ключ ползваме атрибута **[PrimaryKey(nameof(first), nameof(second))]** на ниво таблица.

За несъставни числови и GUID ключове, EF Core автоматично генерира стойности.

Ако не искаме стойностите да се генерират автоматично, ползваме атрибута **`[DatabaseGenerated(DatabaseGeneratedOption.None)]`**.

Можем да ползваме стратегията **`HiLo`** чрез метода **`UseHiLo()`**.

Можем също така да дефинираме алтернативни ключове.
#### Generated Values
**Стойности по подразбиране (Default Values)**

- Можем да зададем стойност по подразбиране чрез метода `.HasDefaultValue()`. Пример:
    
```csharp
modelBuilder.Entity<Blog>()
    .Property(b => b.Rating)
    .HasDefaultValue(3);
```
    
- Също така можем да ползваме SQL функция за генериране на стойност по подразбиране чрез `.HasDefaultValueSql()`. Пример:
    
```csharp
modelBuilder.Entity<Blog>()
    .Property(b => b.Created)
    .HasDefaultValueSql("getdate()");
```

**Изчисляеми колони (Computed Columns)**

- За изчисляеми стойности ползваме метода `.HasComputedColumnSql()`. Пример:

```csharp
modelBuilder.Entity<Person>()
    .Property(p => p.DisplayName)
    .HasComputedColumnSql("[LastName] + ' ' + [FirstName]");
```

- Можем да зададем изчисляемата стойност като `stored: true`, което означава, че стойността ще бъде физически съхранявана в базата данни и няма да се пресмята при всяко дърпане на данни в базата. Ще се генерира колона, която ще пази съответната стойност. Пример:

```csharp
modelBuilder.Entity<Person>()
    .Property(p => p.NameLength)
    .HasComputedColumnSql("LEN([LastName]) + LEN([FirstName])", stored: true);
```

Тези подходи ни позволяват да автоматизираме присвояването на стойности в базата данни и да осигурим по-добра консистентност на данните.
#### Indexes
По конвенция индексите се добавят към пропъртитата, които представляват външни ключове (може да бъде изключено).

На ниво таблица можем да ползваме атрибута **`[Index]`**.

За индекс по една колона ползваме **`[Index(nameof(prop))]`**.

За съставен индекс ползваме **`[Index(nameof(first), nameof(second))]`**.

За уникален индекс ползваме **`[Index(nameof(prop), IsUnique = true)]`**.

**Index with additional included columns that are not part of the key:**

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<MyEntity>()
        .HasIndex(e => e.Column1)
        .IncludeProperties(e => new { e.AdditionalColumn, e.AdditionalColumn2 });
}
```

В този пример създаваме индекс върху **`Column1`**.

Използваме **`IncludeProperties`** за да добавим **`AdditionalColumn`** и **`AdditionalColumn2`** в индекса, но те не са част от ключа.

Това е полезно за оптимизация на заявки, които често включват тези допълнителни колони, без те да бъдат част от основния ключ.

**Check Constraint:**

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<MyEntity>()
        .ToTable(b => b.HasCheckConstraint("CH_Prices", "[Price] > [DiscountedPrice]"));
}
```

Тук се добавя **check constraint** към таблицата, който гарантира, че стойността на **`Price`** е по-голяма от **`DiscountedPrice`**.

**`HasCheckConstraint`** задава правило, което се прилага към данните в таблицата, предотвратявайки въвеждането на невалидни стойности.

EF Core предлага три стратегии за работа с наследяване в модели на ентити. Препоръчително е да се избягва наследяването, когато е възможно, поради възможни проблеми с производителността и сложността.
#### Inheritance Strategies
Желателно е да избягваме наследяването. EF Core предлага три стратегии за работа с наследяване в модели на ентити. Препоръчително е да се избягва наследяването, когато е възможно, поради възможни проблеми с производителността и сложността.

1. **TPH (Table Per Hierarchy)** – Стандартна стратегия

- Всички класове в йерархията се съхраняват в една таблица.

- Използва се дискриминаторна колона за разграничаване на типовете.

- Това е стандартната стратегия в EF Core и е подходяща за повечето случаи, но може да доведе до излишни колони и стойности `null`.

2. **TPT (Table Per Type)**

- Всяка класа има своя собствена таблица.

- Може да се използва чрез **`.UseTptMappingStrategy()`** в конфигурацията.

- Използва се, когато искаме да запишем различни типове в отделни таблици, но може да има малко по-големи разходи за производителността.

3. **TPC (Table Per Concrete Type)**

- Всеки тип има своя отделна таблица, но данните са денормализирани.

- Използва споделена последователност за идентификаторите.

- Подходяща, когато искаме да избегнем наследяването, но да съхраним конкретни данни за всеки тип отделно.
#### Spatial Data
Пространствените данни изискват допълнителни пакети за работа с EF Core:

- За **SQL Server**: ползваме пакета `Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite`
    
- За **PostgreSQL**: ползваме пакета `Npgsql.EntityFrameworkCore.PostgreSQL.NetTopologySuite`

```csharp
protected override void OnConfiguring(DbContextOptionsBuilder options)
{
    options.UseSqlServer(
        "Server=.;Database=MyDatabase;Trusted_Connection=True;",
        x => x.UseNetTopologySuite());
}
```

Тези пакети добавят поддръжка за пространствени типове данни като точки, линии и полигони. Получаваме възможност да работим с координати, като разполагаме с ширина (**latitude**) и дължина (**longitude**). Това ни позволява да извършваме различни пространствени търсения.

Например, ако имаме база данни с всички върхове в България, можем:
- Да зададем текущата си позиция по координати и да потърсим **най-близките върхове**.

- Да изчислим **разстоянието** между нашата позиция и определен връх.

Тези възможности правят пространствените данни изключително полезни при изграждането на географски базирани услуги.

Поддържаните типове включват: **`Geometry`**, **`Point`**, **`LineString`**, **`Polygon`** и други.

Важно е да се отбележи, че:

- **X** представлява дължина (**Longitude**).
    
- **Y** представлява ширина (**Latitude**).  
    Тази подредба е обърната спрямо стандартното възприемане на координатите.

За **PostgreSQL** е необходимо да активираме разширението **`postgis`:**

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.HasPostgresExtension("postgis");
}
```

Този метод декларира, че базата данни трябва да включва разширението **`PostGIS`**, което е необходимо за работа с пространствени данни.

[Microsoft SQL Server Database Provider - Spatial Data - EF Core | Microsoft Learn](https://learn.microsoft.com/en-us/ef/core/providers/sql-server/spatial)

[Spatial Mapping with NetTopologySuite | Npgsql Documentation](https://www.npgsql.org/efcore/mapping/nts.html?tabs=ef9-with-connection-string)

[NetTopologySuite | NetTopologySuite](https://nettopologysuite.github.io/NetTopologySuite/)
#### Miscellaneous
##### Sequences
Можем да добавим последователност (**sequence**) в модела, която например да служи като част от система за номериране.

Пример:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.HasSequence<int>("InvoiceNumber", schema: "dbo")
        .StartsAt(1000)
        .IncrementsBy(1);

    modelBuilder.Entity<Invoice>()
        .Property(i => i.Number)
        .HasDefaultValueSql("NEXT VALUE FOR dbo.InvoiceNumber");
}
```

В този пример:

- Създаваме последователност **`InvoiceNumber`**, която започва от **1000** и се увеличава с **1**.
    
- Полето **Number** в таблицата **Invoice** получава автоматична стойност от тази последователност.

Това е полезно при системи за фактуриране, поръчки или други нумерационни схеми.
##### Value Converters
Позволяват преобразуване на стойности при четене и запис в базата данни.

Пример за конвертиране на **boolean** стойности в низове **"Yes"** и **"No"**:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<User>()
        .Property(u => u.IsActive)
        .HasConversion(
            v => v ? "Yes" : "No",       // Convert true to "Yes" and false to "No" when saving to the database
            v => v == "Yes"               // Convert "Yes" to true, otherwise false when reading from the database
        );
}
```

В този пример:

- При запис, `true` се преобразува в `"Yes"`, а `false` в `"No"`.
    
- При четене, `"Yes"` се интерпретира като `true`, а всяка друга стойност като `false`.

Пример с използване на **`Enum.Parse`** за конвертиране на стойности между **enum** и база данни:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<User>()
        .Property(u => u.Status)
        .HasConversion(
            v => v.ToString(),          // Convert enum value to string when saving to the database
            v => (UserStatus)Enum.Parse(typeof(UserStatus), v)  // Convert string back to enum when reading from the database
        );
}
```
    
В този пример:

- При запис в базата данни, **enum** стойността се преобразува в низ чрез метода **`ToString()`**.
    
- При четене от базата данни, низът се преобразува обратно в **enum** стойност чрез **`Enum.Parse`**.

**`Enum.Parse`** се използва, за да преобразува низа обратно в съответния **enum** тип, като хвърля изключение, ако низът не съвпада с някоя от стойностите на **enum**.

**Value Converters** са полезни, когато данните в базата и в приложението се представят по различен начин.
##### Initial Data Seeding
**Инициализация на данни** се отнася до процеса на запълване на базата данни с начални данни при създаването й или при прилагане на миграции. Ето някои важни точки относно този процес:

- **Основните ключове**, въпреки че обикновено се генерират от базата данни, трябва да бъдат експлицитно предоставени по време на инициализацията. Това е необходимо, защото те се използват за проследяване на промените между миграциите.
    
- Записите, които са добавени чрез инициализация, ще бъдат **премахнати при следваща миграция**, ако техните основни ключове се променят. Това се случва, защото **Entity Framework Core** проследява записите чрез техните основни ключове, и ако ключът на даден запис се промени, се счита, че оригиналният запис вече не съществува.

Ето пример за как да имплементираме инициализация на данни в **EF Core**:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<User>().HasData(
        new User { Id = 1, Name = "John Doe", Email = "johndoe@example.com" },
        new User { Id = 2, Name = "Jane Smith", Email = "janesmith@example.com" }
    );
}
```

В този пример:

- **Основните ключове** (`Id` в този случай) са експлицитно зададени.
    
- Инициализираните данни ще бъдат използвани при първоначалното прилагане на миграцията. Обаче, ако основните ключове на тези записи бъдат променени в бъдеща миграция, те ще бъдат считани за нови записи или ще бъдат премахнати.

Това е важен процес за осигуряване на последователност и интегритет на данните по време на миграциите.
##### Splitting
**Table Splitting**:

- **Table Splitting** означава, че няколко **Entity** класа се картографират към една таблица в базата данни.
    
- Понякога искаме да запазим обектно-ориентираната композиция на класовете, но това може да не съвпада добре с релационния модел на базата данни.

Пример за **Table Splitting**: Ако имаме два класа **Person** и **`PersonDetails`**, искаме тези класове да се картографират към една таблица в базата данни, за да избегнем излишни таблици, като например една за **Person** и друга за **`PersonDetails`**. Това може да бъде полезно за оптимизация на производителността.

Пример в **EF Core**:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<Person>()
        .ToTable("People");

    modelBuilder.Entity<PersonDetails>()
        .ToTable("People");
}
```

**Entity Splitting**:

- **Entity Splitting** означава, че един **Entity** клас се разделя и картографира към повече от една таблица.
    
- Това не се препоръчва, защото може да доведе до усложняване на архитектурата и да създаде неясноти в структурата на данните.

Пример за **Entity Splitting** (не препоръчвано): Ако имаме един клас **Person**, но той се разделя на две таблици (например, една за лични данни и друга за контактни данни), това може да доведе до проблеми при поддръжка и управление на базата данни.
### Queries
#### Overview
**Client vs. Server Evaluation**:

- **Client Evaluation** означава, че част от заявката се обработва в клиента след като данните са извлечени от базата данни.
    
- **Server Evaluation** означава, че цялата заявка се изпълнява на сървъра, преди да се върнат данните към клиента, което обикновено е по-ефективно.

**Tracking vs. No-Tracking Queries**:

- **Tracking Queries** се използват за наблюдение на промените в обектите, така че да може да се извършват актуализации след извличането им от базата данни.
    
- **No-Tracking Queries** не проследяват промените в обектите, което прави заявките по-бързи и по-ефективни, когато няма нужда от проследяване на състоянието на обектите.

**Loading Related Data**:

- **Eager Loading** зарежда свързаните данни веднага с основния обект.
    
- **Explicit Loading** зарежда свързаните данни по-късно чрез изрична заявка.
    
- **Lazy Loading** зарежда свързаните данни автоматично, когато те са необходими, т.е. при достъп до тях.
#### Related Data and Serialization
Препоръчва се да **използваме** **DTO** или **`ViewModel`** вместо да сериализираме директно **Entity** класове. Това ни позволява да изпращаме само необходимите данни, да предотвратим изтичане на чувствителни данни и да имаме по-добър контрол върху валидацията и трансформацията на данните.

Ако държим да сериализираме ентити моделите:

```csharp
public void ConfigureServices(IServiceCollection services)
{
    services.AddControllers()
        .AddJsonOptions(options =>
        {
            options.JsonSerializerOptions.ReferenceHandler = System.Text.Json.Serialization.ReferenceHandler.IgnoreCycles;
        });
}
```

Това ще настрои **JSON сериализацията** така, че при наличие на циклични зависимости (например когато един обект съдържа препратки към друг, който също препраща към първия), те ще бъдат игнорирани и няма да предизвикат изключения. **`ReferenceHandler.IgnoreCycles`** ще предотврати циклични зависимости, като просто игнорира обектите, които вече са били сериализирани, вместо да предизвика безкраен цикъл.
#### Split Queries
EF използва оператора **JOIN** за зареждане на свързани данни.

Въпреки че **JOIN** е стандартна операция в RDBMS, той може да доведе до проблеми с производителността.

**Картезианска експлозия**:

Това се случва, когато навигационни свойства са включени на същото ниво.

Пример: Ако един блог има 10 публикации и 10 автори, ще бъдат върнати 100 реда, което може да доведе до сериозни проблеми с производителността.

```csharp
var blogs = context.Blogs
    .Include(b => b.Posts)
    .Include(b => b.Author)
    .ToList();
```

**Data Duplication**

В примера по-горе, когато включваме навигационни свойства като **Posts** и **Authors**, всеки от 100-те реда ще съдържа всички колони от **Blog**. Това води до **Data Duplication**, което може да доведе до сериозно забавяне. При такова повторение, много данни се връщат многократно, което води до значително намаляване на производителността.

**Решение**

Един от начините за решаване на проблема с **Data Duplication** и **Performance Impact** е използването на **Split Query**. Това е техника, при която заявката се разделя на две или повече части вместо да се извършва само една.

**Split Query**

**Split Query** се използва, за да се раздели заявката на две или повече части. Първо, основните данни се зареждат с първата заявка, а после свързаните данни (като **Posts** и **Authors**) се зареждат с отделни заявки. Това елиминира проблема с **Data Duplication**, тъй като всяка заявка връща само съответните данни.

Пример за Split Query в EF Core:

```csharp
var blogs = context.Blogs
    .Include(b => b.Posts)
    .Include(b => b.Authors)
    .AsSplitQuery()
    .ToList();
```

Това ще изпълни две отделни SQL заявки:

1. Първата заявка зарежда **Blog** данни.
    
2. Втората заявка зарежда **Posts**, свързани с тези **Blogs**.

Кога да използваме **Single Query** срещу **Split Query**?

Няма строг регламент кога да използваме една заявка срещу разделена заявка, но е полезно да разгледаме: 

- **Single Query** е по-подходящ за малки набори от данни, когато всички свързани данни не са толкова големи и когато няма сериозна загуба на производителност.
    
- **Split Query** е по-добре за по-големи набори от данни, когато има големи колони, които могат да предизвикат проблеми с производителността и да водят до **Data Duplication**. Струва си да се пробва, когато имаме много бавна заявка (например, когато времето за изпълнение е над половин секунда).

По подразбиране **EF** използва **Single Query** за зареждане на свързани данни. Ако искаме да използваме **Split Query**, трябва изрично да маркираме заявката.

Разделянето на заявките чрез **Split Query** помага да се избегне натоварването на системата и да се подобри производителността, като същевременно се намалява излишното повторение на данни.

**Split Query** в **EF Core** има своите предимства, но също така носи някои рискове и ограничения, които трябва да се вземат предвид. Ето основните неща, които трябва да знаете:

- **Консистентност в рамките на една заявка:** Базите данни обикновено гарантират консистентност при изпълнение на една заявка, но при използване на Split Query, съществува риск от **извличане на остарели данни**, които вече са били променени, тъй като всяка заявка се изпълнява поотделно.
    
- **Допълнителни мрежови операции:** Когато се използват Split Query, всяка заявка е допълнителна **мрежова операция**, което може да доведе до проблеми, когато има висока **мрежова латентност**. Това увеличава времето за обработка на заявката и може да забави приложението.
    
- **Batching на заявки:** Някои бази данни поддържат изпълнение на **няколко заявки в пакет** (batching), но повечето не го правят. Това означава, че резултатите от Split Query трябва да бъдат **кеширани в паметта**, което може да доведе до **повишена консумация на паметта** в приложението.
    
- **`Пагинация` с Split Query:** При използване на **пагинация** (например **`Skip()` / `Take()`**) с Split Query е важно да се уверите, че **сортирането гарантира уникалност** на резултатите. Това е важно, защото без правилно сортиране, при определени условия може да се получат дублиращи се записи или да се пропуснат записи.

Обобщение:

- **Split Query** е полезен, когато има много навигационни свойства и желаете да избегнете дублирането на данни.
    
- Въпреки това, трябва да се внимава за потенциални проблеми с **остарели данни**, **мрежова латентност**, **повишено потребление на памет** и **неправилно сортиране при пагинация**.
#### `GroupBy`
**LINQ `GroupBy`**:

- Резултатът от **LINQ `GroupBy`** оператор е **`IGrouping<TKey, TElement>`**, който имплементира интерфейса **`IEnumerable<TElement>`**.
    
- Това позволява **по-нататъшна обработка с LINQ**, като например филтриране, сортиране или проектиране на резултатите след групирането.
    
Пример:

Ако имаме списък с продукти и искаме да ги групираме по категория, можем да използваме **`GroupBy`**:

```csharp
var products = new List<Product>
{
    new Product { Name = "Apple", Category = "Fruits" },
    new Product { Name = "Banana", Category = "Fruits" },
    new Product { Name = "Carrot", Category = "Vegetables" },
};

var groupedProducts = products
    .GroupBy(p => p.Category)
    .Select(g => new
    {
        Category = g.Key,
        Products = g.ToList()
    });

foreach (var group in groupedProducts)
{
    Console.WriteLine($"Category: {group.Category}");
    foreach (var product in group.Products)
    {
        Console.WriteLine($"- {product.Name}");
    }
}
```

Обяснение:

- **`IGrouping<TKey, TElement>`** съдържа **ключ** (в случая категорията) и **елементи** (в случая продуктите от съответната категория).
    
- Можем да обработим групираните резултати, като използваме LINQ методи като **`Select`**, **`Where`**, **`OrderBy`**, и други.

**Базите данни нямат концепцията за `IGrouping`**, което е причината повечето LINQ **`GroupBy`** заявки да не могат да бъдат директно преведени на SQL.

SQL операторът **GROUP BY** има някои ограничения:

- Може да групираме само по **скаларни стойности** (като стойности от колони, а не обекти или сложни типове).

- Проекцията (резултатът от запитването) може да включва само колони, които са част от ключа или са агрегираните колони (например използване на **COUNT**, **SUM**, **AVG** и т.н.).

**Как EF обработва `GroupBy`**:

- **EF анализира заявката** и я превежда на SQL, ако тя отговаря на условията, които SQL изисква.
    
- В някои случаи, започвайки от **EF Core 7**, групирането може да се приложи **след изпълнението на заявката**. Това означава, че EF може да извърши групирането в паметта след извличането на данните, вместо директно в SQL заявката.

Пример:

Ако имаме следната LINQ заявка:

```csharp
var result = context.Orders
    .GroupBy(o => o.CustomerId)
    .Select(g => new 
    { 
        CustomerId = g.Key, 
        TotalAmount = g.Sum(o => o.Amount) 
    })
    .ToList();
```

EF Core ще се опита да преведе **`GroupBy`** на SQL, но ако условията на SQL не позволяват директното групиране, например ако включваме допълнителни изчисления или сложни обекти, групирането може да бъде извършено след като данните са изтеглени от базата данни и обработени в паметта.

Проблеми:

- Това може да доведе до **лоша производителност**, особено когато групирането се прави върху големи количества данни, защото цялата информация трябва да бъде извлечена преди да може да се приложи групирането в паметта.
#### Global Query Filters
**Глобалните филтри** се добавят към метаданните на модела и се прилагат автоматично към всяко запитване, включително тези за навигационни свойства.
    
Най-често се използват за:
    
- **Меко изтриване (Soft Delete)**: Филтрира записи с `isActive = false`.
        
- **Многостепенно наемане (Multi-tenancy)**: Филтрира записи по `tenantId` за всеки наемател.


Пример за Soft Delete:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<MyEntity>().HasQueryFilter(m => m.IsActive);
}
```

Пример за Multi-Tenancy:

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<MyEntity>().HasQueryFilter(m => m.TenantId == _currentTenantId);
}
```

**Предимства**: Удобство и консистентност, тъй като не е нужно да добавяме филтри във всяко запитване.

**Използване на Required навигационни свойства с активен глобален филтър** може да доведе до изключване на основния ентити от резултата, тъй като това се превръща в **INNER JOIN** в SQL. Това се случва, когато глобалният филтър води до елиминиране на записи, които не отговарят на условията на филтъра.

Изключване на глобални филтри за специфично запитване:

За да **деактивираме глобалните филтри** за определено запитване, можете да използваме метода `IgnoreQueryFilters()`:

Пример:

```csharp
var blogsWithoutFilters = context.Blogs
    .Include(b => b.Posts)
    .IgnoreQueryFilters()
    .ToList();
```

Това премахва всички глобални филтри, приложени към `Blogs` ентити, и позволява получаване на всички записи, независимо от активираните глобални филтри като **Soft Delete** или **Multi-tenancy**.
### Concurrency
**Управление на конфликти в конкурентна среда:**

Съществуват два основни подхода за управление на конфликти:

1. **Оптимистичен (Optimistic):**
    
    - Предполага, че конфликтите са рядкост.
        
    - Действията се предприемат след възникване на конфликт.
        
    - Това е по подразбиране стратегия в EF.
        
2. **Песимистичен (Pessimistic):**
    
    - Заключва данните преди обработка.
        
    - Обезпечава актуалността на данните, но блокира едновременните заявки.

**Как EF Core управлява конкурентността:**

EF Core използва **оптимистичния подход**, като конфигурира поле като **конкурентен токен**. Това поле се зарежда и следи, а при актуализиране се сравнява със стойността в базата данни.

**Конкурентни токени генерирани от базата данни:**

- За **MS SQL Server** използваме атрибута **[Timestamp]**, като базата генерира стойност при всяко **Insert** или **Update**.
    
- За **PostgreSQL** се използва **`xmin`** за проследяване на последната транзакция, която е модифицирала реда.

**Конкурентни токени, управлявани от приложението:**

- За бази данни, които не поддържат автоматично генериране на токени (като **SQLite**), можем да използваме **[`ConcurrencyCheck`]** атрибут.
    
- При тези токени, имаме контрол върху времето за генериране на токена, което помага да избегнем ненужни конфликти.
## `CinemaApp` Project
### Layered Architecture
![](https://github.com/GerardSh/SoftwareUniversity/blob/main/99%20Attachments/Pasted%20image%2020250319141406.png)

Архитектурата на приложението е изградена върху няколко слоя, всеки от които има специфична роля:

1. **Data Layer**

    Това е слой, който съдържа моделите, които осъществяват директната комуникация с базата данни. Той отговаря за извършване на заявки, манипулиране на данни и взаимодействие с базата. Този слой е свързан с конкретната имплементация на базата данни и е отговорен за всичко, свързано с нея.

2. **Web Layer**

	Този слой на приложението, е напълно независим от базата данни. Приложението се изгражда на база наличните данни в базата. Например, ако базата съдържа информация за филми, създаваме приложение за управление на филми. Важното е, че типът на базата данни не трябва да има значение — приложението трябва да работи независимо от това коя база е използвана. Основната му задача е да осигури визуализация на данни и взаимодействие с потребителите чрез UI/UX, без да се интересува откъде идват тези данни. Независимо дали данните идват от база данни, файл или памет, Web слоя знае, че трябва да чете и записва данни и да предоставя възможности за взаимодействие на потребителите. Голямото предимство тук е, че Web слоя не зависи от източника на данни — ако сменим базата данни или технологиите, всичко, което трябва да променим, е съответният слой, докато Web слоя остава същият. Това прави приложението много по-гъвкаво и лесно за пренасяне към различни среди и източници на данни.

3. **Service / Business Logic Layer**  

	Layer-a за бизнес логика се намира между слоя за данни (Data) и уеб приложението (Web) и играе ключова роля в комуникацията между тях. Например, когато уеб приложението трябва да покаже на потребителя всички филми, то изпраща заявка към съответната услуга (service). Тази услуга знае какви стъпки да предприеме, за да извлече необходимите данни.

	В случая, уеб приложението извиква услуга като **`GetAllMovies`**, която съдържа бизнес логика, определяща как правилно да се извлекат всички филми чрез заявка към базата данни. Получените резултати се връщат обратно към уеб приложението във вид на **`MoviesViewModel`**. Уеб приложението след това представя тези данни във визуален формат (UI/UX), без да се налага допълнително преобразуване.

	Цялата логика, свързана с това кои филми да се извлекат (например изключване на изтритите филми), се реализира в слоя за бизнес логика. Именно тук се изграждат заявките (например чрез LINQ), които се предават към слоя за данни (Data). Data моделите от своя страна генерират съответните SQL заявки, които се изпълняват върху базата данни.

	Резултатите се връщат чрез **`DbContext`** под формата на **`IEnumerable<T>`** или **`IQueryable<T>`**. В слоя за бизнес логика може да се прецени кога заявката трябва да бъде материализирана или дали даден обект трябва да бъде закачен или разкачен към контекста.

	Основната цел на слоя за бизнес логика не е просто да извлече данните, а и да ги трансформира в подходящ формат, така че уеб приложението да ги получи в готов вид за визуализация.

	В идеалния случай уеб приложението не трябва да преобразува данните – неговата задача е само да ги валидира и подаде на по-долните слоеве. Същото важи и в обратната посока – когато данните се връщат към уеб приложението, то просто ги визуализира в изгледа (View), без да се налага допълнителна обработка. Тази структура осигурява ясен разделение на отговорностите и улеснява поддръжката и разширяемостта на системата.

4. **Common Layer**  

	Този слой съдържа споделена информация и ресурси, достъпни за всички останали слоеве на приложението. Той обикновено включва глобални конфигурации, общи данни и функционалности, които осигуряват консистентност в работата на системата. Поради своята роля тези ресурси често се наричат „глобалки“ и са предназначени да бъдат достъпни от всеки слой в приложението.

**Предимства на архитектурата:**

- **Лесна разширяемост**: Архитектурата позволява лесно добавяне на нови приложения, като например конзолни приложения, които се свързват през сървисите. Това означава, че можем да добавяме нови функционалности без да променяме базата данни - можем да създадем приложение само за дебъгване на базата данни, без да добавяме допълнителни функционалности.
    
- **Преносимост**: Приложението може лесно да бъде пренесено към различни среди. Ако променим базата данни или някаква друга технология, единственото, което трябва да променим, е съответният слой (Data Layer), докато останалите слоеве остават непроменени.
    
- **Отделяне на отговорностите**: Всеки слой има ясно дефинирана роля и отговорности, което прави кода по-разбираем, по-лесен за поддръжка и разширяване.

Тази архитектура е особено полезна при необходимост от дебъгване на базата данни или други операции, които изискват изпълнение извън Web слоя. Например, създаването на отделно конзолно приложение, което да работи като дебъг инструмент, може да бъде много удобно за тестове и проверка на правилната работа на базата данни или на функционалността на сървисите, без да се налага да работим с цялото приложение.
### Identity
Data слоят съдържа начална миграция, която включва всички таблици от Identity системата на ASP.NET. 
ASP.NET предоставя много функционалности наготово, включително тази система за удостоверяване и управление на потребители.

Identity системата позволява на потребителите да създават акаунти, да се вписват, да възстановяват забравени пароли и да получават имейли за потвърждение или възстановяване на достъп. Тази система функционира като вграден framework във framework-а.

Когато посочим, че искаме да ползваме Identity, ASP.NET автоматично генерира необходимите таблици. Те включват:

- Потребители
- Роли на потребителите
- История на влизанията
- Асоциация между потребители и техните роли
- Таблици за токъни и други свързани данни

Този подход улеснява значително внедряването на система за удостоверяване в приложенията.
#### `ApplicationUser` Model
```csharp
public class ApplicationUser : IdentityUser<Guid>
{
    public ApplicationUser()
    {
        Id = Guid.NewGuid();
    }
}
```

Този модел разширява стандартния клас `IdentityUser` на Entity Framework, което позволява промяна на типа на **Primary Key** му, който по подразбиране е от тип **string**. Използването на **GUID** за основен ключ е било необходимо, защото по-старите версии на EF Core не са поддържали **GUID** като тип за Primary Key. В миналото е било практика да се използва **GUID**, като се извиква методът `ToString()`. Въпреки това, с по-новите версии на EF Core вече е възможно да се използва директно **GUID**, което осигурява по-голяма сигурност и уникалност на идентификаторите.
### DbContext Constructor
```csharp
        public CinemaDbContext(DbContextOptions<CinemaDbContext> options)
            : base(options)
        {
        }
```

Този конструктор се използва от уеб приложението чрез dependency injection, което автоматично подава необходимите опции за конфигурация на контекста.
### Comment Attributes
Коментарите, които добавяме в ентити моделите чрез атрибути, представляват специални коментари, които Entity Framework третира и включва в базата данни като коментари към съответните колони или таблици. Това дава възможност на DB инженерите да разбират защо даден елемент е създаден по този начин в контекста на Code First модела, което помага за по-доброто поддържане и разширяване на базата данни.
### Entity Level Filters
```csharp
entity.HasQueryFilter(e => e.IsDeleted == false)
```

Можем да добавяме **query filters** на глобално ниво, така че всички заявки към дадено ентити автоматично да взимат само тези записи, които отговарят на условието. При използване на **soft delete**, обикновено искаме да извличаме само записите, за които `IsDeleted` е `false`. За да постигнем това, в бизнес логиката, където правим заявки, трябва да извършваме филтрация. Това може да се осигури глобално, на ниво запитване, като добавим филтър към всички заявки за съответното ентити/таблица в метода **`OnModelCreating`** на контекста на базата данни.
### Best Practices for Code Clarity and Specification Reference
За да подобрим яснотата и поддръжката на кода, е добра практика да се избягва използването на магически низове и числа в кода. Вместо това, трябва да дефинираме константи или конфигурационни настройки за стойности, които се използват многократно, като например дължини на колони, формати на числа и т.н. Този подход улеснява актуализирането на стойности и осигурява яснота относно тяхното значение.

Освен това, когато следваме определени спецификации, стандарти или изисквания (като вътрешни насоки на компанията, регулаторни правила или клиентски спецификации), е добра идея да добавим препратка към съответната спецификация или документ в кода. Това осигурява контекст за използваната стойност и гарантира, че бъдещи разработчици могат лесно да проследят оригиналната спецификация, ако е необходимо.

Ето как може да изглежда такъв коментар:

```csharp
// It's good to avoid magic strings and numbers in the code
// Also, cite the specification or standard that justifies this value
/// <summary>
/// SWS_Cinema_EntityValidation_700152878: Cinema name should be able to store text with length up to 256
/// </summary>
public const int NameMaxLength = 256;
```

В този пример:

- Коментарът обяснява стойността и защо е избрана така.
- Коментарът в `summary` предоставя препратка към конкретна спецификация (в случая `SWS_Cinema_EntityValidation_700152878`), която ясно показва причината за избор на дължината `256` за името на киното.

Тази практика прави кода самодокументиращ се и помага на бъдещите разработчици лесно да разберат контекста на взетите решения, както и че кодът остава в съответствие с външни спецификации и стандарти.
### Seeding
Имаме няколко начина за seed-ване на данни:

1. **`Fluent API`** 

	Използва се методът `.HasData()` във Fluent API, който генерира миграция, съдържаща seed данните за базата. За целта трябва да създадем метод в конфигурационния файл на съответното ентити, който генерира необходимите обекти и ги връща като колекция. След това този метод се подава като аргумент на `.HasData()`.
    
    **Предимства:**
    
    - След като apply-нем миграциите, данните автоматично ще бъдат добавени в базата.
    - Ако приложението се стартира на друга машина, миграциите ще се apply-нат и данните ще се seed-нат автоматично.
    
    **Недостатък:**
    
    - Този подход е по-подходящ за development среда. В production не е препоръчителен, тъй като seed-натите данни може да създадат ненужен шум в базата.

2. **Custom Seed Method / Custom Seed Class** 
	При този подход импортваме данни от външен източник (например файл или мрежа), десериализираме ги и създаваме нови ентитети в базата.
    
    **Предимства:**
    
    - Много гъвкав и конфигурируем подход.
    - Подходящ за production среда, тъй като може да се управлява условно — например да се изпълнява само в development среда или при нужда.
    - Не създава излишен шум в базата при production разгръщане.

	Този подход предлага по-голям контрол и се препоръчва за по-сложни сценарии или когато работим с големи обеми от данни.
### Web Application Builder
В ASP.NET Core файлът `Program.cs` съдържа метода `WebApplication.CreateBuilder()`, който създава уеб приложение, базирано на определени настройки и параметри. След като приложението бъде конфигурирано чрез този метод, тези параметри не могат да бъдат променяни.

**Конфигурация**

Един от ключовите параметри е **`ConfigurationManager`**, който извлича конфигурационни данни от конфигурационни файлове като:

- `appsettings.json` — използва се при разгръщане на приложението.
- `appsettings.Development.json` — съдържа настройки за development среда.
- **Secret Storage** — предпочитаният вариант за съхранение на чувствителна информация като connection strings, тъй като е локален за машината и по-сигурен от `appsettings.json`.

> [!NOTE]
> Ако една и съща конфигурационна стойност съществува и в `appsettings.json`, и в `secrets.json`, ще бъде взета стойността от `secrets.json`.

**Регистриране на услуги (Services)**

ASP.NET Core разчита на механизма **Dependency Injection** (DI) за управление на зависимостите.

- Услугите (services) се регистрират в **Service Collection** — голяма колекция, подобна на речник (dictionary), която съдържа всички инстанции на обектите, необходими на приложението.
- Тази колекция съдържа както стандартни ASP.NET услуги, така и наши собствени custom услуги.

Пример за регистриране на `DbContext` в Service Collection:

```csharp
builder.Services.AddDbContext<AppDbContext>(options =>
    options.UseSqlServer(builder.Configuration.GetConnectionString("DefaultConnection")));
```

**Как работи Dependency Injection**

Когато ASP.NET Core изпълнява метод или конструктор, който очаква параметър от определен тип (например `DbContext`), той търси този тип в Service Collection.

Примерен метод с DI:

```csharp
public void MyMethod(AppDbContext dbContext)
{
    // Използване на dbContext
}
```

ASP.NET Core ще потърси в Service Collection ключ, съответстващ на типа `AppDbContext`. Ако го намери, ще подаде инстанцията като стойност на параметъра.

- Ако типът не е регистриран в Service Collection, ще бъде генерирана грешка за unresolved зависимост.

**Жизнени цикли на услугите (Service Lifetimes)**

Услугите могат да бъдат регистрирани с различен обхват (lifetime):

- **Singleton** — Една-единствена инстанция се създава за целия живот на приложението.
- **Transient** — Нова инстанция се създава при всяко заявяване на услугата, дори в рамките на един и същи обхват.
- **Scoped** — В рамките на една заявка се създава само една инстанция. При следваща заявка ще бъде създадена нова инстанция.

Пример за регистрация на услуги с различен обхват:

```csharp
builder.Services.AddSingleton<ISingletonService, SingletonService>();
builder.Services.AddTransient<ITransientService, TransientService>();
builder.Services.AddScoped<IScopedService, ScopedService>();
```

Този модел осигурява гъвкавост и контрол върху жизнения цикъл на обектите в приложението, което е ключово за ефективното управление на ресурсите.

**`AddDatabaseDeveloperPageExceptionFilter()`**

`AddDatabaseDeveloperPageExceptionFilter` се използва за добавяне на филтър за изключения, когато приложението е в режим на разработка (Development). Този филтър осигурява подробна информация за изключенията, които се случват в базата данни, и показва допълнителна информация за грешките, свързани с Entity Framework Core.

Това е полезно за разработчиците, тъй като позволява да се получат подробни съобщения за грешки и стек трасировки, свързани с операциите върху базата данни, което улеснява откриването на проблеми по време на разработка.

Този филтър трябва да се използва само в режим на разработка и не трябва да бъде включен в производствената среда, защото може да разкрие чувствителна информация за базата данни или структурата на приложението.

**`AddDefaultIdentity<T>()`**

`AddDefaultIdentity` е метод в ASP.NET Core, който конфигурира стандартната система за идентификация и управление на потребители (authentication и authorization). Той автоматично добавя необходимите услуги за управление на потребители, роли и сигурност, включително пароли и удостоверяване. Методът също така предоставя готов интерфейс за регистрация и вход, който може да се персонализира. Методът `AddEntityFrameworkStores` се използва за конфигуриране на конкретен `DbContext`, който да се използва от системата за идентификация. По подразбиране, когато се добавя идентификация, се създава собствен `DbContext` за потребителите и ролите. Чрез `AddEntityFrameworkStores`, можем да посочим конкретен контекст, който да бъде използван за съхранение на данни за потребители, роли и други свързани със сигурността елементи.

**`AddControllersWithViews()`**

Методът `builder.Services.AddControllersWithViews()` в ASP.NET Core се използва за добавяне на поддръжка за контролери и изгледи (views) към приложението. Това означава, че приложението ще бъде настроено да работи с MVC архитектура, като се осигурява възможност за използване на контролери, които обработват HTTP заявки, и връщат изгледи за рендиране на потребителите.

След добавянето на необходимите услуги, методът `Build()` се използва за изграждане на конфигурирания `WebApplication`, който е готов за стартиране и изпълнение. Този процес създава финалния обект на приложението, който съдържа всички конфигурации и регистрирани услуги.

Същността на този процес е да се добавят всички необходими услуги за MVC и след това да се създаде приложението чрез `Build()`, което позволява стартирането на уеб приложението.
### Copy files to Output Directory on Build
Когато работим върху реален проект, който ще бъде деплойнат, е важно да създадем папка с файловете, които ще използваме и да зададем правилните **Build Action** за тези файлове.

По-точно:

1. **Създаване на папка с файлове**: Тези файлове могат да бъдат ресурси, конфигурационни файлове или други необходими файлове за приложението.

2. **Настройване на Build Action**: За да гарантираме, че файловете ще бъдат включени в build процеса, трябва да отидем в Properties на файловете и да зададем **Build Action** на "Copy Always" или "Copy if newer". Това означава, че файловете ще бъдат копирани в директорията, където се събира крайният output на приложението (работната директория). Това променя `.csproj` файла, като добавя информация за копирането на файловете в изходната директория при билдване на проекта.

3. **Работна директория**: При изграждането на проекта, тези файлове ще бъдат копирани в работната директория на приложението, което е важно за достъпването им чрез относителни пътища. Така когато приложението се изпълнява, ще може да достъпва файловете в работната директория, а не в директорията на изходния код.

4. **Проблем при деплойване**: Когато деплойваме приложението, ние обикновено деплойваме само **работната директория** и нейното съдържание. Ако файловете са част от изходния код (в source code директорията), те няма да бъдат включени в деплоймента и ще възникне проблем, ако се опитваме да ги достъпим по пътя към тях. Затова е важно да ги преместим в работната директория и да ги настроим така, че да се копират по време на build процеса.
# ChatGPT
## Using "Paste Special" in Visual Studio to Quickly Create DTO Objects from JSON or XML

In Visual Studio, you can use the **"Paste Special"** feature to quickly generate DTO (Data Transfer Object) classes from JSON or XML data. This allows you to avoid manually defining classes for complex structures.

**Steps to Generate DTO Classes from JSON or XML:**

1. **Copy the JSON or XML data**:
    
    - Copy the structure of the JSON or XML that you want to convert into a C# DTO class.
2. **Paste Special in Visual Studio**:
    
    - In Visual Studio, right-click where you want the DTO class to be created (usually in your `Models` or `DTOs` folder).
    - From the context menu, select **Edit** > **Paste Special** > **Paste JSON as Classes** (for JSON) or **Paste XML as Classes** (for XML).
3. **Automatically Generated Classes**:
    
    - Visual Studio will generate the corresponding C# class or classes with properties that map to the structure of the JSON or XML data.
4. **Usage**:
    
    - You can now use these generated classes to deserialize incoming JSON or XML into C# objects using `JsonSerializer.Deserialize<T>` for JSON or `XmlSerializer.Deserialize<T>` for XML.

**Example:**

For JSON:

1. **JSON data**:
    
```json
{
  "id": "123",
  "name": "Movie Title",
  "genre": "Action",
  "releaseDate": "2023-01-01"
}
```
    
2. **Generated DTO class** using **Paste JSON as Classes**:
    
```csharp
public class RootObject
{
    public string Id { get; set; }
    public string Name { get; set; }
    public string Genre { get; set; }
    public DateTime ReleaseDate { get; set; }
}
```
    

Now you can easily deserialize the JSON data into the `RootObject` class:

```csharp
string jsonString = "{\"id\":\"123\",\"name\":\"Movie Title\",\"genre\":\"Action\",\"releaseDate\":\"2023-01-01\"}";
RootObject movie = JsonSerializer.Deserialize<RootObject>(jsonString);
```

Benefits:

- **Saves time**: Automatically generates DTOs based on the structure of JSON/XML data.
- **Consistency**: Ensures that the class structure matches the data format, reducing human error.
- **Flexibility**: Easily adapts to any new JSON or XML structure.

This approach is great when working with external APIs or large datasets where defining DTO classes manually can be cumbersome.
# Misc
## Parametrized Queries
Когато заявките ни са параметризирани и подаваме различни стойности на параметрите, те работят по-бързо, отколкото когато подаваме директно стойности. Това е така, защото при параметризираните заявки оптимизаторът изготвя плана за изпълнение само веднъж и го ползва повторно за различните стойности на параметрите. При директно подаване на стойности, оптимизаторът трябва да създава нов план за всяка стойност, което води до допълнителен разход на ресурси и време.
# Bookmarks
Spatial Data External Links:

[Microsoft SQL Server Database Provider - Spatial Data - EF Core | Microsoft Learn](https://learn.microsoft.com/en-us/ef/core/providers/sql-server/spatial)

[Spatial Mapping with NetTopologySuite | Npgsql Documentation](https://www.npgsql.org/efcore/mapping/nts.html?tabs=ef9-with-connection-string)

[NetTopologySuite | NetTopologySuite](https://nettopologysuite.github.io/NetTopologySuite/)